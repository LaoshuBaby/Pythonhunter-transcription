[00:00.000 --> 00:02.920] 第8个 刚才信涛也说了一个经验问题
[00:02.920 --> 00:04.320] 我觉得经验当然是很好的
[00:04.320 --> 00:06.640] 经验最好的一点就是在面对问题的时候
[00:06.640 --> 00:08.800] 能够让你走捷径 shortcut
[00:08.800 --> 00:10.560] 能够让你一步就走到那个地方
[00:10.560 --> 00:12.720] 但其实我并不欣赏这一点
[00:12.720 --> 00:14.400] 因为问题是无穷无尽的
[00:14.400 --> 00:17.400] 人在学习更多新东西的时候
[00:17.400 --> 00:19.040] 总是会面对未知的问题
[00:19.040 --> 00:20.720] 所以我更看重的是
[00:20.720 --> 00:22.880] 你如何去分析一个未知的问题
[00:22.880 --> 00:25.680] 如何去找到正确的路径去做这个事情
[00:25.680 --> 00:28.800] 最重要的不是工具而是思路
[00:28.800 --> 00:31.120] 你要成为工具的主人而不是工具的奴隶
[00:31.120 --> 00:34.800] 不要觉得我不会什么工具我就不能去debug
[00:34.800 --> 00:39.440] 要克服这种困难思想
[00:41.840 --> 00:43.120] 各位听众朋友们大家好
[00:43.120 --> 00:44.800] 欢迎来到这一期的捕食者说
[00:44.800 --> 00:47.840] 我是这一期的主持人赖鑫涛
[00:47.840 --> 00:51.519] 这一期我们又请到了Grey
[00:51.519 --> 00:53.600] 来跟我们一起聊一聊debug的经历
[00:53.600 --> 00:57.200] Grey其实之前有参与过一期捕食者说
[00:57.200 --> 00:59.680] 但是我们那一期节目还在剪辑中
[00:59.680 --> 01:04.480] 所以Grey的两期节目应该很快会和大家见面
[01:04.480 --> 01:07.200] 这一期和我一起录制的主播还有
[01:07.200 --> 01:09.120] MandrySaka和Lakai9M
[01:09.120 --> 01:10.640] Hello大家好
[01:10.640 --> 01:12.000] 自我介绍就不用了吧
[01:13.920 --> 01:16.480] 那我们让Grey来自我介绍一下吧
[01:16.480 --> 01:18.960] 因为这两期不一定哪一期先出来
[01:20.080 --> 01:21.760] 好的好的感谢
[01:21.760 --> 01:24.640] 我是姓涛的同事和粉丝
[01:24.640 --> 01:30.400] 工作经历是以前第一份工作干的是土木
[01:30.400 --> 01:32.640] 后来转到写python
[01:32.640 --> 01:36.560] 然后现在主要写golang
[01:36.560 --> 01:37.440] 谢谢大家
[01:40.800 --> 01:42.320] Grey太谦虚了
[01:42.320 --> 01:43.440] 其实我是他的粉丝
[01:43.440 --> 01:44.480] 我是他的小弟
[01:47.040 --> 01:48.800] OK那我们就直奔主题
[01:48.800 --> 01:51.520] 我们先从大家的debug经历开始聊
[01:51.520 --> 01:54.720] 我们就让Grey先聊一聊
[01:54.720 --> 01:58.320] 他遇到的最难的debug的一些经历吧
[01:58.320 --> 01:59.440] 好谢谢
[01:59.440 --> 02:05.360] 其实最难的话就觉得可能会不太接地气
[02:05.360 --> 02:09.120] 其实我一直想先说一下
[02:09.120 --> 02:11.039] debug一些很多关键的东西
[02:11.039 --> 02:13.920] 就是说今天可能会涉及很多debug工具
[02:13.920 --> 02:15.840] 但是我觉得最重要的不是工具
[02:15.840 --> 02:17.120] 而是思路
[02:17.120 --> 02:19.519] 你要成为工具的主人
[02:19.519 --> 02:20.560] 而不是工具的奴隶
[02:20.560 --> 02:22.880] 不要觉得我不会什么工具
[02:22.880 --> 02:24.640] 我就不能去debug
[02:24.640 --> 02:31.120] 要克服这种困难思想
[02:31.120 --> 02:33.040] 然后很多困难的bug
[02:33.040 --> 02:36.000] 它也不一定涉及高超的技术原因
[02:36.000 --> 02:39.440] 很可能是弱智的bug
[02:39.440 --> 02:43.520] 所以说就算今天涉及到很多的工具的讨论
[02:43.520 --> 02:46.320] 但希望听众也不要觉得
[02:46.320 --> 02:49.200] 我不会这些工具我就不能debug了
[02:49.200 --> 02:53.440] 所以我先分享一个bug不涉及很复杂的工具
[02:53.440 --> 02:57.679] 反而涉及一些很重要的debug的思想和思路
[02:57.679 --> 03:00.079] 是我在2017年的时候
[03:00.079 --> 03:01.359] 我还在写python的时候
[03:01.359 --> 03:03.920] 然后有一位同事晚上加班的时候
[03:03.920 --> 03:06.160] 他说搞了好几个小时都不知道怎么办
[03:06.160 --> 03:07.679] 他的服务是这样的
[03:07.679 --> 03:09.440] 他的服务是一个http服务
[03:09.440 --> 03:14.799] 然后这个服务是在允许你在浏览器访问之后
[03:14.799 --> 03:16.079] 上传一个pdf
[03:16.080 --> 03:20.960] 然后服务会返回你一个ms的excel
[03:20.960 --> 03:23.440] excel.sx的文件
[03:23.440 --> 03:26.000] 然后这个服务在你本地运行的时候
[03:26.000 --> 03:27.760] 在他本地运行的时候是好的
[03:27.760 --> 03:30.160] 浏览器上传然后会返回下载
[03:30.160 --> 03:32.000] 但是一旦这个服务上线
[03:32.000 --> 03:35.520] 上到线上的容器里的时候就不行了
[03:35.520 --> 03:37.840] 从浏览器访问就什么都没有
[03:37.840 --> 03:39.120] 什么都没有
[03:39.120 --> 03:41.040] 然后这个问题的话
[03:41.040 --> 03:45.280] 比较典型
[03:45.280 --> 03:46.320] 对是这样的
[03:46.320 --> 03:47.600] 因为一开始我拉手的时候
[03:47.600 --> 03:49.600] 我的主要思想是先抓个包
[03:49.600 --> 03:52.320] 浏览器发了请求从浏览器抓包
[03:52.320 --> 03:54.000] 这是第一个怪事就来了
[03:54.000 --> 03:54.720] 浏览器抓包
[03:54.720 --> 03:57.440] 打开network inspector
[03:57.440 --> 03:58.400] 什么请求都没有
[03:58.400 --> 04:00.320] 我点了上传文件
[04:00.320 --> 04:01.600] 点那个上传之后
[04:01.600 --> 04:03.840] 浏览器抓包一片空白
[04:03.840 --> 04:05.760] 网络浏览那一片是一片空白
[04:05.760 --> 04:06.560] 什么请求都没有
[04:06.560 --> 04:07.760] 这是第一个怪事
[04:07.760 --> 04:08.960] 我从来没遇到这种情况
[04:08.960 --> 04:13.200] 然后同时这边点上传之后
[04:13.200 --> 04:15.359] 服务端那边的日志
[04:15.359 --> 04:17.039] Python Flask写的
[04:17.039 --> 04:18.959] 应用程的日志说是有输到的
[04:18.959 --> 04:20.240] 甚至说有返回
[04:20.240 --> 04:21.200] 这就更怪了
[04:21.200 --> 04:22.960] 浏览器居然说没有包
[04:22.960 --> 04:24.320] 但是应用程返回了
[04:24.320 --> 04:25.920] 我现在甚至不知道是哪一块出了问题
[04:25.920 --> 04:27.920] 是客户端出了问题
[04:27.920 --> 04:28.880] 还是服务端出了问题
[04:28.880 --> 04:29.840] 还是中介出了问题
[04:29.840 --> 04:32.800] 然后接下来我改用curl
[04:32.800 --> 04:34.960] 用curl命名行Curl
[04:34.960 --> 04:39.039] 发请求在本地发远程的请求
[04:39.039 --> 04:40.719] 然后这是第二个怪事出现了
[04:40.719 --> 04:42.719] 它返回了东西
[04:42.720 --> 04:45.280] 但返回的是我不认识的返回
[04:45.280 --> 04:46.880] 返回了一个100continue
[04:46.880 --> 04:49.680] 现在我知道100continue它是什么含义
[04:49.680 --> 04:51.920] 它在ACCPRFC里面
[04:51.920 --> 04:53.840] 到底是怎样去约定的返回
[04:53.840 --> 04:55.520] 但当时我根本就不知道
[04:55.520 --> 04:58.080] 居然华语户有请求会返回100continue
[04:58.080 --> 05:00.640] 然后它的行为是返回100continue之后
[05:00.640 --> 05:02.240] 就没有别的动静
[05:02.240 --> 05:03.200] 没有别的response
[05:03.200 --> 05:06.000] 然后整个请求就卡在那等东西
[05:06.000 --> 05:07.520] 等完之后就超时了
[05:07.520 --> 05:10.960] 这两个行为都很奇怪
[05:10.960 --> 05:11.920] 我从来没有见过
[05:11.920 --> 05:14.240] 所以当时就很能理解
[05:14.240 --> 05:16.480] 为什么我这个同事就整个卡几个小时
[05:16.480 --> 05:17.280] 不知道怎么办
[05:19.760 --> 05:21.680] 但实际上这个问题最后非常简单
[05:21.680 --> 05:26.240] 你只要把curl请求搬到线上容器里去运行
[05:26.240 --> 05:28.880] 我之前curl是在我本地的电脑上
[05:28.880 --> 05:30.320] 去发线上容器
[05:30.320 --> 05:32.800] 你只要把curl请求搬到线上容器里
[05:32.800 --> 05:35.280] 去请求容器里面
[05:35.280 --> 05:38.320] 这样绕开了它中间的网络
[05:38.320 --> 05:39.440] 所有的网络设备
[05:39.440 --> 05:42.240] 然后立刻就能成功
[05:42.240 --> 05:44.240] 只要做了这一件事
[05:44.240 --> 05:45.520] 你立刻就能确定
[05:45.520 --> 05:47.280] 一定是中间的网络层的问题
[05:47.280 --> 05:50.000] 而不是说你的服务哪里的代码有问题
[05:50.000 --> 05:54.320] 或者说你中间Flask有什么东西文档没读全
[05:54.320 --> 05:57.040] 或者有什么坑没有遇到过
[05:57.040 --> 05:57.360] 对
[05:57.360 --> 05:58.400] 一开始我们也怀疑过
[05:58.400 --> 06:00.480] 是Flask有什么坑我们遇到了
[06:00.480 --> 06:03.280] 比如说Flask返回文件用的是SendFile
[06:03.280 --> 06:05.920] 还是什么样的一个内部API
[06:05.920 --> 06:08.240] 我们会想会不会说我们不了解这个API
[06:08.240 --> 06:12.560] 它有什么行为是在不同的部署环境上有变化的
[06:12.560 --> 06:13.520] 这是有可能的
[06:13.520 --> 06:14.160] 对
[06:14.160 --> 06:17.280] 但最终我们只要做过这一个实验
[06:17.280 --> 06:20.080] 我们只要把curl从本地搬到线上去运行
[06:20.080 --> 06:21.840] 就立刻确定是网络问题
[06:21.840 --> 06:22.640] 确认网络问题
[06:22.640 --> 06:24.240] 我们就一次排查中间网络设备
[06:24.240 --> 06:26.800] 最后确定到是一个Endings的问题
[06:26.800 --> 06:27.680] 对
[06:27.680 --> 06:31.200] 这个问题其实最后看下来结果非常简单
[06:31.200 --> 06:33.280] 而且它最关键的一点只有一步
[06:33.280 --> 06:35.920] 你只要两步
[06:35.920 --> 06:39.600] 第一步是你必须把浏览器
[06:39.600 --> 06:40.880] 它本来是个浏览器的APP
[06:40.880 --> 06:44.080] 你得把这个浏览器行为变成一个curl发送的请求
[06:44.080 --> 06:44.880] 这是第一步
[06:44.880 --> 06:48.720] 第二步你得把本地发送curl变到去容器内部
[06:48.720 --> 06:52.560] 给容器内部的服务发curl请求
[06:52.560 --> 06:53.840] 你只要做完这两步实验
[06:53.840 --> 06:56.640] 立刻就能确定它的问题在哪一步出现的
[06:56.640 --> 06:58.400] 但是就算是这两步
[06:58.400 --> 07:00.400] 中间都有很多很困扰的地方
[07:00.400 --> 07:02.080] 包括Chrome没有返回
[07:02.080 --> 07:03.440] Chrome没有返回的原因是因为
[07:03.440 --> 07:07.120] Chrome的行为是如果请求没有结束
[07:07.120 --> 07:09.200] 比如说它返回了一个100continue
[07:09.200 --> 07:10.080] 那这种情况下
[07:10.080 --> 07:12.800] Chrome是不会显示出这个请求的
[07:12.800 --> 07:13.360] 对
[07:13.360 --> 07:14.960] 它甚至那个request都不会显示出来
[07:14.960 --> 07:16.000] 这个是它的一个特性
[07:16.000 --> 07:16.880] 一个feature
[07:16.880 --> 07:18.560] 现在它会显示pending
[07:18.560 --> 07:19.600] 对
[07:19.600 --> 07:21.360] 我觉得正确的话应该显示pending
[07:21.360 --> 07:23.280] 它应该先显示request
[07:23.280 --> 07:24.640] 对 这样才是正确的
[07:24.640 --> 07:26.640] 包括curl返回100
[07:26.640 --> 07:29.120] 也是如果不了解APP的话也会很疑惑
[07:29.120 --> 07:31.200] 这到底是对的呢还是不对的呢
[07:31.200 --> 07:31.600] 对
[07:31.600 --> 07:33.600] 你就会在这里看这个返回100
[07:33.600 --> 07:35.360] 是不是Flask自己的问题
[07:35.360 --> 07:38.000] 我们发的请求是不是发生了变化
[07:38.000 --> 07:38.400] 对
[07:38.400 --> 07:41.200] Flask是不是有什么地方不对
[07:41.200 --> 07:42.320] 导致它返回100
[07:42.320 --> 07:43.120] 实际上这个100是对的
[07:43.120 --> 07:43.680] 对
[07:43.680 --> 07:44.800] 但这都不重要
[07:44.800 --> 07:48.080] 重要的是你要在这一系列
[07:48.080 --> 07:49.280] 面对bug的时候
[07:49.280 --> 07:51.440] 甚至在debug中间遇到了很多
[07:51.440 --> 07:53.120] 没有遇到过的困难
[07:53.120 --> 07:54.480] 你会怀疑这到底是
[07:54.480 --> 07:55.520] 我从来没见过这种情况
[07:55.520 --> 07:56.400] 这是对还是不对呢
[07:56.400 --> 07:58.800] 你要去善于去做比较
[07:58.800 --> 08:03.280] 你要记着硬着头去往下去找问题
[08:03.280 --> 08:03.920] 对
[08:03.920 --> 08:04.960] 100这个问题
[08:04.960 --> 08:08.800] 实际上当时我们做了另外一个实验
[08:08.800 --> 08:11.840] 就是在本地另外起一个服务
[08:11.840 --> 08:14.240] 然后用curl去发我本地的服务
[08:14.240 --> 08:15.200] 它依然返回100
[08:15.200 --> 08:16.880] 所以说我们做了这个比较之后
[08:16.880 --> 08:18.480] 就知道这个100是正确的行为
[08:18.480 --> 08:20.080] 我们就不管这个返回100
[08:20.080 --> 08:21.600] continue到底是对还是不对了
[08:21.600 --> 08:22.320] 对
[08:22.320 --> 08:22.880] 所以说
[08:22.880 --> 08:28.640] 对这个case实际上是比较简单的一个事情
[08:28.640 --> 08:31.440] 但实际上没有经验的一个程序员
[08:31.440 --> 08:32.799] 甚至说工作两三年
[08:32.799 --> 08:34.000] 稍微有经验的程序员
[08:34.000 --> 08:35.039] 拿到它的时候
[08:35.039 --> 08:39.840] 都不太有清晰的思路去做
[08:39.840 --> 08:41.520] 或者说一开始遇到困难
[08:41.520 --> 08:42.799] 比如说我们为什么抓不到包
[08:42.799 --> 08:44.000] 为什么curl返回100
[08:44.000 --> 08:45.199] 然后之类的问题
[08:45.199 --> 08:47.840] 都会有未来性你做不下去
[08:47.840 --> 08:50.800] 所以说这是我通过这个case
[08:50.800 --> 08:55.280] 希望听众在一开始就要有这样一个印象
[08:55.280 --> 09:01.199] 就是debug其实最重要的还是你要去
[09:01.199 --> 09:02.160] 你要有这个心
[09:02.160 --> 09:04.240] 你要去勇敢的去做下去
[09:04.240 --> 09:05.600] 你会遇到很多未知的困难
[09:05.600 --> 09:06.400] 这是肯定的
[09:06.400 --> 09:09.360] 但是你要坚持不懈的做下去
[09:09.360 --> 09:12.240] 就算遇到了很多你可能以为是bug的
[09:12.240 --> 09:13.680] 你不知道的东西
[09:13.680 --> 09:16.400] 你可以暂时的通过切换工具
[09:16.400 --> 09:19.439] 或者对比正确和不正确的服务的行为
[09:19.439 --> 09:22.160] 来绕开这些你未知的知识点
[09:22.160 --> 09:25.360] 能够减少你的很多心灵障碍
[09:25.360 --> 09:26.959] 当时你排查的时候
[09:26.959 --> 09:28.240] 你为什么没有考虑说
[09:28.240 --> 09:30.480] 我在容器里面去抓包说
[09:30.480 --> 09:32.880] 看我的请求到容器了吗
[09:32.880 --> 09:33.839] 或者是其他的吗
[09:33.839 --> 09:34.800] 就是说是对等的吗
[09:34.800 --> 09:37.199] 就一个是看我客户端把包发出去没有
[09:37.199 --> 09:39.760] 一个是看我服务端收到包没有
[09:40.560 --> 09:41.439] 这很简单
[09:41.439 --> 09:42.640] 因为容器里没有tcp档
[09:42.640 --> 09:45.199] 但是你ns enter进去的话
[09:45.199 --> 09:46.480] 当时也是可以
[09:46.480 --> 09:48.079] 我知道我上不了速度间
[09:48.079 --> 09:50.560] 当时的机器我权限也很低
[09:50.560 --> 09:51.680] 就跟现在我在shopping一样
[09:51.680 --> 09:52.640] 什么权限都没有
[09:52.640 --> 09:53.599] 我进不了速度间
[09:53.599 --> 09:54.479] OK 明白了
[09:54.479 --> 09:57.439] 所以这个问题其实现在想一想
[09:57.439 --> 10:01.760] 就是我们要把浏览器发一个请求到服务器收到
[10:01.760 --> 10:03.599] 然后处理这个过程想明白
[10:03.599 --> 10:04.400] 然后去
[10:04.400 --> 10:06.160] 因为它在本地环境是没问题的
[10:06.160 --> 10:07.680] 所以我们就看在线上的环境
[10:07.680 --> 10:09.599] 它到底经过了哪些中间件
[10:09.599 --> 10:11.920] 这个请求由谁转给了谁
[10:11.920 --> 10:15.520] 看一步一步到底是中间有了谁就有问题
[10:15.520 --> 10:16.479] 没有谁就没有问题
[10:16.479 --> 10:18.560] 这样就可以进一步确认
[10:18.560 --> 10:24.479] 对 但是有很多隐藏的坑可能会出现
[10:24.479 --> 10:25.119] 举个例子
[10:25.119 --> 10:27.199] 这个问题有可能不是出现在中间的网络
[10:27.199 --> 10:29.760] 比如说我们知道Nginx可能会加header
[10:29.760 --> 10:31.040] Nginx可能会加header
[10:31.040 --> 10:32.000] 也可能会删header
[10:32.000 --> 10:35.439] 有没有可能是这种增加和删减header
[10:35.439 --> 10:39.760] 造成的flask的行为在线上行为和本地行为不一样
[10:39.760 --> 10:40.640] 这是完全有可能的
[10:40.640 --> 10:41.040] 对吧
[10:41.040 --> 10:41.839] 或者是我们
[10:41.839 --> 10:42.640] 对对对
[10:42.640 --> 10:43.520] 这种行为是有可能
[10:43.520 --> 10:45.760] 所以说在我们在拿这个问题的时候
[10:45.760 --> 10:48.640] 实际上是完全不知道的
[10:48.640 --> 10:52.640] 虽然是现在想起来这种行为是线上不一致
[10:52.640 --> 10:53.760] 最有可能是网络
[10:53.760 --> 10:55.040] 但也有可能是别的问题
[10:55.040 --> 10:56.640] 对 所以说
[10:56.640 --> 10:57.840] 对 是这样的
[10:57.840 --> 10:59.200] 新涛说的很好
[10:59.200 --> 11:05.920] 我介绍一个算是我第一次遇到一个非常困难的bug
[11:05.920 --> 11:07.040] 也是2017年
[11:07.040 --> 11:08.960] 也是一个http的问题
[11:08.960 --> 11:12.400] 就是问题跟环境都比较相像
[11:12.400 --> 11:14.720] 就是我当时我有一个博客
[11:14.720 --> 11:16.720] 我的博客是http服务
[11:16.720 --> 11:21.120] 我想让这整个全站都变成https的
[11:21.120 --> 11:22.560] 如果用户访问http
[11:22.560 --> 11:27.120] 我就把它返回一个重新向到https
[11:27.120 --> 11:28.240] 很简单的一个问题
[11:28.240 --> 11:29.360] 对吧
[11:29.360 --> 11:35.120] 但是我们当时用的那个2017年还是在用那个叫空间
[11:35.120 --> 11:38.960] 很多用户共享一个PHP的同一个物理机
[11:38.960 --> 11:41.120] 然后很久以前是没有docker
[11:41.120 --> 11:43.680] 然后他们一直用这个空间去售卖
[11:43.680 --> 11:45.359] 然后延续到那个时候
[11:45.359 --> 11:46.640] 其实他们还在用这种方式
[11:46.640 --> 11:47.839] 其实是没有用docker的
[11:47.839 --> 11:49.439] 就是做了一些软件的限制
[11:49.439 --> 11:51.040] 当时是叫空间
[11:51.040 --> 11:55.199] 然后我就在我自己的那个空间里设置
[11:55.199 --> 11:59.040] 当时他们服务商只提供apache
[11:59.040 --> 12:00.800] 就是说他给你提供了一系列软件
[12:00.800 --> 12:01.520] 你只能配置
[12:01.520 --> 12:02.880] 但是你不能跑自己的进程
[12:02.880 --> 12:05.760] 我就在里面设置了一个判断
[12:05.760 --> 12:10.240] 如果进来的那个scheme还是protocol
[12:10.240 --> 12:11.120] 就是有一个字段
[12:11.120 --> 12:12.479] 判断如果是http的话
[12:12.480 --> 12:15.040] 我就把它跳转到https
[12:15.040 --> 12:16.640] 对吧
[12:16.640 --> 12:18.240] 就是很简单的一个事情
[12:18.240 --> 12:19.120] 我把这个配置改了
[12:19.120 --> 12:20.480] 然后部署到线上
[12:20.480 --> 12:23.440] 然后我的博客就不能正常访问了
[12:23.440 --> 12:27.200] 就非常的奇怪
[12:27.200 --> 12:31.200] 然后以当时我对http的了解
[12:31.200 --> 12:33.920] 我感觉就是这个配置是没有什么问题的
[12:33.920 --> 12:36.160] 到后来其实我看这个配置也是没有什么问题
[12:36.160 --> 12:37.680] 就在chrome里面
[12:37.680 --> 12:39.280] 它有的时候会出现那个
[12:39.280 --> 12:41.920] 说你重定向的次数过多
[12:41.920 --> 12:45.360] 因为当时我对那个主机的权限也是非常小
[12:45.360 --> 12:47.680] 就是我只能去看它的配置
[12:47.680 --> 12:51.839] 好像日志忘记能不能看了
[12:51.839 --> 12:54.240] 总之非常困难
[12:54.240 --> 12:55.199] 然后我就问了
[12:55.199 --> 13:00.479] 当时去问一下我们公司的另一个经验比较多的人
[13:00.479 --> 13:03.680] 就这个问题其实感觉经验少的话
[13:03.680 --> 13:05.680] 是很难理解到这个
[13:05.680 --> 13:07.120] 就是很难想到是这个问题
[13:07.120 --> 13:12.080] 中间排查的一些过程就不说了
[13:12.080 --> 13:13.280] 其实都没有什么必要
[13:13.280 --> 13:14.880] 然后他最后就说
[13:14.880 --> 13:17.360] 有没有可能就是说
[13:17.360 --> 13:20.880] 这个空间的提供商在最前面
[13:20.880 --> 13:23.040] 把这个http的证书给卸载了
[13:23.040 --> 13:27.680] 然后他们因为是有网关有你的应用
[13:27.680 --> 13:28.880] 网关发给你的应用
[13:28.880 --> 13:31.040] 他总是把那个https卸载了
[13:31.040 --> 13:33.600] 然后用http的方式发给你的应用
[13:33.600 --> 13:34.480] 对吧
[13:34.480 --> 13:37.280] 这样的话可以节省他的一些资源
[13:37.280 --> 13:40.240] 然后因为到了你的应用的那个
[13:40.240 --> 13:42.720] 协议总是http的
[13:42.720 --> 13:45.040] 所以你把用户定向https
[13:45.040 --> 13:47.520] 那用户又去访问你的这个地址
[13:47.520 --> 13:50.320] 那网关又把这个https卸载了
[13:50.320 --> 13:51.360] 又发给你http
[13:51.360 --> 13:53.440] 这样的话就产生了一个这样的重新像
[13:53.440 --> 13:58.160] 然后我就顺着这个思路去查那个空间提供商
[13:58.160 --> 14:01.360] 给的一些https上线的一些文档
[14:01.360 --> 14:03.280] 发现他们确实是这样做的
[14:03.280 --> 14:04.800] 然后他们在文档里说
[14:04.800 --> 14:07.439] 你如果要强制重新上的话
[14:07.439 --> 14:10.480] 你不能判断就是原始的那些header
[14:10.480 --> 14:13.520] 你要判断空间提供商给你发的一个
[14:13.520 --> 14:15.439] 那个http请求
[14:15.439 --> 14:19.199] 就是会带一个x-original-protocol
[14:19.199 --> 14:20.240] 这么一个东西
[14:20.240 --> 14:23.120] 这样的话因为发给你的总是http
[14:23.120 --> 14:25.839] 但是这个header空间提供商
[14:25.839 --> 14:27.120] 那个网关发给你的时候
[14:27.120 --> 14:29.360] 他会告诉你最原始的那个协议
[14:29.360 --> 14:31.439] 到底是http还是https
[14:31.440 --> 14:34.480] 这个就是我印象比较深的遇到的最
[14:34.480 --> 14:39.120] 算是我遇到第一个自己解决不了的bug吧
[14:39.120 --> 14:41.680] 后来的想法就是
[14:41.680 --> 14:44.480] debug确实是需要一些经验的
[14:44.480 --> 14:51.280] 在一些有限的资源
[14:51.280 --> 14:52.640] 比如说你的权限有限
[14:52.640 --> 14:54.640] 你的知识有限
[14:54.640 --> 14:58.800] 遇到的这些问题积累一下
[14:58.800 --> 15:02.319] 是比较有用的
[15:02.319 --> 15:04.160] 包括后来遇到的一些问题
[15:04.160 --> 15:08.160] 就是说你之前没有遇到过类似的问题
[15:08.160 --> 15:10.000] 像是信号那些东西
[15:10.000 --> 15:13.599] 就自己很难去想到是这方面的问题
[15:13.599 --> 15:15.280] 所以说需要
[15:15.280 --> 15:17.760] 我觉得是需要一些经验的积累
[15:17.760 --> 15:23.760] 然后我其实说到https
[15:23.760 --> 15:26.800] 我印象最深的一个bug也是关于https
[15:26.800 --> 15:30.079] 就是之前听众看我的之前分享的文章和
[15:30.079 --> 15:31.040] asyncio
[15:31.040 --> 15:33.040] 是的经典的asyncio
[15:33.040 --> 15:35.439] 你们知道这个具体的细节吗
[15:35.439 --> 15:37.199] 不知道你可以讲一讲
[15:37.199 --> 15:40.880] 就是在标准SL模型里面
[15:40.880 --> 15:43.439] 然后就说是标准SL模型里面
[15:43.439 --> 15:46.240] 然后就说你可能说你建立连接的时候
[15:46.240 --> 15:48.000] 你会说去发say hello
[15:48.000 --> 15:51.359] 就是说是会有一个就交换密钥的过程
[15:51.359 --> 15:54.560] 然后但是你在SL里面
[15:54.560 --> 15:57.839] 然后因为它毕竟是over就是说是TCP的
[15:57.839 --> 16:01.439] 然后他可能说他就说你TCP连接可能没有关
[16:01.439 --> 16:03.520] 但是你要代表着当前的SL
[16:03.520 --> 16:05.599] 就是说是TLS的一个session结束了
[16:05.599 --> 16:08.800] 然后你需要去发一个就是说是shutdown的请求
[16:08.800 --> 16:11.439] 就是他在里面是有个shutdown的一个
[16:11.439 --> 16:12.959] 就一个过程
[16:12.959 --> 16:16.239] 就是在就类似于就所谓的TCP的40回首
[16:16.239 --> 16:17.839] 不过在SL里面一声两不
[16:17.839 --> 16:21.359] 就是说是主动关闭的一方发动一个发起一个shutdown
[16:21.359 --> 16:23.599] 然后发起一个shutdown之后呢
[16:23.600 --> 16:27.520] 然后被关闭的那一方也要回一个shutdown
[16:27.520 --> 16:29.920] 然后就告诉就你双方这个radio
[16:29.920 --> 16:33.840] 但是在早期版本就是3.6 3.7 3.8
[16:33.840 --> 16:35.840] 横跨几个大版本的sync IO里面
[16:35.840 --> 16:37.360] sync IO里面之后呢
[16:37.360 --> 16:40.960] 然后他去shutdown的这个SL
[16:40.960 --> 16:44.720] 他去shutdown的他给上面发了一个shutdown了
[16:44.720 --> 16:48.640] 然后服务器给他回到shutdown他不处理
[16:48.640 --> 16:52.160] 然后但是他还会持有这个TCP连接
[16:52.160 --> 16:56.079] 然后在一些就代理的情况下
[16:56.079 --> 16:59.360] 比如说Nix之前一些版本还有那个Apache
[16:59.360 --> 17:01.120] 就是就是传统的两个嘛
[17:01.120 --> 17:04.319] 他们发回了shutdown之后或者是发了shutdown之后
[17:04.319 --> 17:07.200] 会去关闭这个就是说是就看你配置
[17:07.200 --> 17:10.000] 有些配置情况下就会关闭这个TCP连接
[17:10.000 --> 17:11.520] 但是问题就来了
[17:11.520 --> 17:14.639] 然后关闭了TCP他关闭了TCP连接
[17:14.639 --> 17:18.079] 然后你这边一直是在搞搞搞搞
[17:18.079 --> 17:21.200] 然后最后就导致说close wait的那个数量
[17:21.200 --> 17:24.480] 一直在不断的就是说你的连接没法释放
[17:24.480 --> 17:26.960] 一直在增多增多增多增多
[17:26.960 --> 17:30.720] 对然后所以说最后导致的问题就是说是
[17:30.720 --> 17:33.840] 当时我线上的服务
[17:33.840 --> 17:37.760] 我线上的服务其实就是说是那个
[17:37.760 --> 17:42.400] 连接数当时的表象就是说
[17:42.400 --> 17:46.320] 我的那个文件描述服务数一直在增多
[17:46.320 --> 17:49.840] 我第一阶段就是说可能会把这个
[17:49.840 --> 17:56.800] 我想想就是把这个文件描述服务数量给调大
[17:56.800 --> 18:00.480] 然后我当时可能说只是觉得线上我犯了第一个错误
[18:00.480 --> 18:02.639] 其实这个是造成了一定经济损失的
[18:02.639 --> 18:04.320] 就是说我犯了第一个错误
[18:04.320 --> 18:06.800] 就是说我没有去查他的rot course
[18:06.800 --> 18:08.800] 就是说我只是觉得说
[18:08.800 --> 18:11.919] 我只是觉得说这个地方
[18:11.919 --> 18:15.760] 我只是觉得他可能说因为线上和其他东西
[18:15.760 --> 18:19.920] 然后没有就是说是压力大了
[18:19.920 --> 18:22.000] 然后文件消费多了
[18:22.000 --> 18:24.800] 然后可能说我其他东西就了
[18:24.800 --> 18:28.960] 然后于是我去找运维把文件描述服务调大了
[18:28.960 --> 18:32.080] 但是服务然后就是重启了
[18:32.080 --> 18:34.320] 然后那么ok了一段时间
[18:34.320 --> 18:35.440] 这里我犯了一个错误
[18:35.440 --> 18:37.040] 就是说我没有找到他rot course
[18:37.040 --> 18:39.280] 就是说我没有形成一个完整的因果链
[18:39.280 --> 18:42.640] 就是说是到底什么样的地方会导致说
[18:42.640 --> 18:45.200] 我没法及时释放或是其他的
[18:45.200 --> 18:49.440] 然后后面的代价就是说是有一天我线上服务
[18:49.440 --> 18:52.000] 然后突然又集中的爆了一波
[18:52.000 --> 18:54.960] 然后我看到增加的描述服务的东西
[18:54.960 --> 18:56.560] 然后就是说是CPU非常高
[18:56.560 --> 18:57.440] 水位非常高
[18:57.440 --> 19:00.080] 因为你TCP连接也是非常耗资源的
[19:00.080 --> 19:04.800] 当时最高一台机器干到了4万多活的连接吧
[19:04.800 --> 19:06.960] 4万多然后就close with
[19:06.960 --> 19:10.480] 然后就导致说造成一定经济损失
[19:10.480 --> 19:12.000] 这个时候我才去查
[19:12.000 --> 19:15.280] 然后也是其实就还是传统的老几版腐
[19:15.280 --> 19:18.160] 然后首先抓包抓包看到说
[19:18.160 --> 19:21.600] 然后就看到就具体的行为
[19:21.600 --> 19:24.560] 就是我当时在一个最小的版本上去跑了一段时间复现
[19:24.560 --> 19:26.640] 然后当然这包分析也是
[19:26.640 --> 19:28.320] 就是说ok后面再聊
[19:28.320 --> 19:32.480] 然后就发现就导致说我服务端发过来的东西
[19:32.480 --> 19:33.680] 我这边没有响应
[19:33.680 --> 19:37.360] 然后我就怀疑是可能框架的问题
[19:37.360 --> 19:38.480] 可能怀疑框架
[19:38.480 --> 19:42.240] 因为当时我们刚刚切到AsyncIO加上AIO HTTP
[19:42.240 --> 19:44.960] 那么我去怀疑框架的问题
[19:44.960 --> 19:48.320] 然后最后定位到就说是这个东西
[19:48.320 --> 19:50.480] 然后最后一套因果链
[19:50.480 --> 19:52.720] 因为在饿了吗的时候就说是
[19:52.720 --> 19:53.840] 当然这是饿了吗
[19:53.840 --> 19:55.200] 我在饿了吗之后才学的
[19:55.200 --> 19:58.320] 然后江哥当时告诉我说
[19:58.320 --> 20:00.560] 就说你去查问题的时候
[20:00.560 --> 20:02.960] 你一定要去查出它的一个因果链
[20:02.960 --> 20:04.960] 就什么是因什么是果
[20:04.960 --> 20:07.440] 就说你一定要把这个因果链套出来
[20:07.440 --> 20:11.200] 然后最终查了一个最终你控制范围的一个Root Cause
[20:11.200 --> 20:14.880] 然后那么像我这个case它的Root Cause就是
[20:14.880 --> 20:18.960] AsyncIO它没法去
[20:18.960 --> 20:23.040] 它没有按照标准的去处理Shutdown的这个东西
[20:23.040 --> 20:24.960] 它的底层依赖SL那个东西
[20:24.960 --> 20:26.400] 它没有按照标准去处理
[20:26.400 --> 20:28.000] 于是它发了Shutdown之后
[20:28.000 --> 20:29.520] 然后对端毁了Shutdown
[20:29.520 --> 20:32.480] 但是它没有处理对端发了Shutdown关闭连接
[20:32.480 --> 20:33.920] 因为配置关闭连接
[20:33.920 --> 20:34.880] 关闭连接之后
[20:34.880 --> 20:38.640] 然后AsyncIO这边一直还在保持这个连接
[20:38.640 --> 20:40.960] 就导致说它是被关闭放TCP里面
[20:40.960 --> 20:43.440] 四次回收里面它进入了一个Close way的状态
[20:43.440 --> 20:44.880] 连接一直没法释放
[20:44.880 --> 20:47.280] 然后这个东西然后连接一直没法释放
[20:47.280 --> 20:48.640] 文件描述幅度增高
[20:48.640 --> 20:51.760] 导致我CPU的那个水位上升
[20:51.760 --> 20:54.880] 导致我其他的服务没法正常的对内部提供服务
[20:54.880 --> 20:56.960] 然后这套因果链就拉通了
[20:56.960 --> 20:58.400] 然后因就是这个
[20:58.400 --> 21:00.400] 然后最后的话是用了
[21:00.400 --> 21:04.480] 就AIOHTTP里面的一个当时的一个参数
[21:04.480 --> 21:05.440] 就是一个Fishel
[21:05.440 --> 21:08.080] 就是我去不做绘画保持
[21:08.080 --> 21:09.760] 就我不附用连接
[21:09.760 --> 21:12.000] 我处理完一个连接我就关
[21:12.000 --> 21:13.600] 我处理完一个连接就关
[21:13.600 --> 21:14.800] 我不附用连接
[21:14.800 --> 21:16.400] 然后这一套东西就这样
[21:16.400 --> 21:17.440] 这个印象还挺深的
[21:17.440 --> 21:21.920] 当时就犯我记犯了新手犯了常见查问题的
[21:21.920 --> 21:24.000] 就觉得说可能我先应付过去
[21:24.000 --> 21:27.600] 又说又是后面又查到的原因
[21:27.600 --> 21:30.560] 虽然这个问题我也没暂时没法去解决这个东西
[21:30.560 --> 21:33.040] 因为修改签设的面还挺广的
[21:33.040 --> 21:36.000] 所以说这是一个酷的bug
[21:36.000 --> 21:38.320] 是AIOHTP里面有问题
[21:38.320 --> 21:40.320] 没有,syncIO的
[21:40.320 --> 21:42.800] syncIO它底层依赖CIO的问题
[21:42.800 --> 21:44.159] 那个有BPO
[21:44.159 --> 21:48.720] BPO是30698和那个30698和29406
[21:48.720 --> 21:52.879] OK,是python的问题竟然是
[21:52.879 --> 21:54.000] 对是的
[21:54.000 --> 21:57.200] 其实到现在这个版本我怀疑都还在存在
[21:57.200 --> 22:00.080] 因为这个这两个其实都后来没有那个
[22:00.080 --> 22:04.080] 就没有去最新的一个update了
[22:04.080 --> 22:06.480] 所以说我怀疑现在的问题可能都还存在
[22:06.480 --> 22:08.399] 只是说可能触发条件比较苛刻
[22:08.399 --> 22:10.960] 因为你需要对端那边配置的
[22:10.960 --> 22:14.800] 就是说他发了下他的行为要求是他发了下down之后
[22:14.800 --> 22:19.280] 他立刻关闭连接才有可能是导致说这样的一个行为
[22:19.280 --> 22:23.120] 对我觉得就是就我们在debug
[22:23.120 --> 22:25.120] 尤其是生产环境特别急的时候
[22:25.120 --> 22:31.600] debug很有可能就是没有那种很宽裕的时间去建立一个银行链
[22:31.600 --> 22:34.719] 然后就想着赶紧去hotfix一下对吧
[22:34.719 --> 22:39.040] 然后他就是不报警或者就是把那个usage降起来就行了
[22:39.040 --> 22:42.320] 然后对因为真的要debug特别花时间
[22:42.320 --> 22:45.199] 是的是的这个其实花了我一周的时间
[22:45.199 --> 22:51.040] 对但是9M刚刚说的那个反应应该是对的
[22:51.040 --> 22:56.320] 就是说线上出了问题第一的任务不是去找到更新
[22:56.320 --> 22:58.320] 而是先把它恢复
[22:58.320 --> 22:59.840] 是的对
[22:59.840 --> 23:03.200] 但是我们一般可以留一个instance
[23:03.200 --> 23:06.480] 比如说有多个服务器我们可以把其他的都处理掉
[23:06.480 --> 23:08.480] 然后留一个把它关掉流量
[23:08.480 --> 23:10.480] 然后我们事后再来排查
[23:10.480 --> 23:14.399] 然后就是说是你可以先留现场
[23:14.399 --> 23:18.320] 但是就是说你的这些问题就是即便在弄完之后
[23:18.320 --> 23:22.240] 当然优先可能就是说按照医生他们急诊有句话叫做
[23:22.240 --> 23:26.000] 先救命后治病
[23:26.000 --> 23:28.080] 然后对SRE也是一样
[23:28.080 --> 23:33.040] 然后就是先止血后查根因
[23:33.040 --> 23:37.280] 但是可能就是说是你止血之后还是要花时间去把这些根因
[23:37.280 --> 23:40.399] 就尽可能留一些现场去把这根因复现下来
[23:40.399 --> 23:42.000] 就是说你后面要么就不查
[23:42.000 --> 23:45.200] 要么你查的时候就还是说要把这个因果链
[23:45.200 --> 23:47.120] 就是rotkos给推倒出来
[23:47.120 --> 23:50.159] 行然后我讲一下我经历吧
[23:50.159 --> 23:53.520] 其实就是我觉得还是挺神奇的
[23:53.520 --> 23:57.919] 就是你们就能把自己debug的东西记得那么清楚
[23:57.919 --> 24:03.199] 然后就是我感觉我很多当时就觉得很神奇的bug后来都忘记了
[24:03.199 --> 24:05.199] 但是我现在印象比较深的一个是
[24:05.199 --> 24:06.800] 就其实我不是我自己debug
[24:06.800 --> 24:08.080] 而是我帮别人debug
[24:08.080 --> 24:11.679] 就是大概是应该是去年这个时候吧
[24:11.679 --> 24:13.679] 然后他那个bug其实
[24:13.680 --> 24:17.200] 就是可能比较涉及业务逻辑多一些
[24:17.200 --> 24:20.080] 然后所以他bug本身倒不是重点
[24:20.080 --> 24:24.240] 但那个同学算是一个我带的人吧
[24:24.240 --> 24:27.120] 然后他当时在有一个feature
[24:27.120 --> 24:28.320] 在做一个feature
[24:28.320 --> 24:30.240] 然后就那个feature实现完了
[24:30.240 --> 24:33.360] 但是就是一直他说就是有bug
[24:33.360 --> 24:34.160] 然后再debug
[24:34.160 --> 24:37.680] 然后我觉得卡了差不多等会得有一个月吧
[24:37.680 --> 24:40.560] 然后后来我实在受不了了
[24:40.560 --> 24:42.880] 我就说要不我帮你看一下吧
[24:42.880 --> 24:45.760] 然后后来我就跟他约了一个那种一小时
[24:45.760 --> 24:48.000] 就是一小时的算是pair programming
[24:48.000 --> 24:49.760] 然后我帮他看
[24:49.760 --> 24:52.480] 后来反正是在那个一小时之内解决了
[24:52.480 --> 24:54.320] 然后我就想了一下
[24:54.320 --> 24:57.920] 后来就是为什么他会卡这么久呢
[24:57.920 --> 25:02.400] 第一个我觉得是可能还是有一些认知方面的问题
[25:02.400 --> 25:06.560] 就是他可能不太清楚整个就是代码是怎么工作的
[25:06.560 --> 25:10.720] 所以就是他会尤其面对困难
[25:10.720 --> 25:12.960] 他会有可能会有一些这种为难情绪吧
[25:12.960 --> 25:14.160] 刚才Grey也提到
[25:14.160 --> 25:16.240] 然后就是工具方面的问题
[25:16.240 --> 25:19.680] 就我当时确定那个bug很重要的一步
[25:19.680 --> 25:24.160] 就是去直接看那个我们有个测试数据库里的数据嘛
[25:24.160 --> 25:26.640] 然后我很确定他是没有看这部
[25:26.640 --> 25:28.800] 所以他可能是一直比如说在看代码
[25:28.800 --> 25:29.920] 然后我也不知道发生了什么
[25:29.920 --> 25:34.560] 第三个就是我觉得如果你实在是遇到一些困难
[25:34.560 --> 25:38.480] 可能你就应该适时的去寻求一些帮助
[25:38.480 --> 25:41.360] 因为我觉得卡一个月这种
[25:41.360 --> 25:43.600] 说实话还是挺不应该的
[25:43.600 --> 25:46.240] 然后如果你在第一个星期就去寻求帮助的话
[25:46.240 --> 25:47.840] 可能第一星期就解决了
[25:47.840 --> 25:49.440] 最后结果其实是一样
[25:49.440 --> 25:53.840] 所以我觉得就是有这样一些困难
[25:53.840 --> 25:56.000] 然后之后在那个debug经验的时候
[25:56.000 --> 25:58.000] 也可以去再进一步的做讨论
[25:58.000 --> 26:00.000] 我觉得说的挺好的
[26:00.000 --> 26:01.520] OK
[26:01.520 --> 26:03.920] 那我们现在再聊一下
[26:03.920 --> 26:06.800] 就是大家遇到的比较有趣的bug吧
[26:06.800 --> 26:09.680] 我可以先讲一个就是我之前在频道上分享过的
[26:09.680 --> 26:12.800] 就是当时是在上一家公司的时候
[26:12.800 --> 26:13.760] 我们用语雀嘛
[26:13.760 --> 26:15.280] 其实是触发了一个语雀的bug
[26:15.280 --> 26:16.320] 其实也不算bug
[26:16.320 --> 26:18.080] 因为基本上只有我自己遇到
[26:18.080 --> 26:20.240] 就是说我们不是用control e
[26:20.240 --> 26:22.159] 可以跳到那个在打字的时候
[26:22.159 --> 26:23.600] 可以跳到那个行尾吗
[26:23.600 --> 26:24.240] 对
[26:24.240 --> 26:25.680] 是emacs的快捷键
[26:25.680 --> 26:30.320] 在mac上大部分的输入的可以允许输入的地方都是支持的
[26:30.320 --> 26:33.360] 然后当时遇到的一个问题就是我按control e
[26:33.360 --> 26:35.600] 他总是就是不会跳到行尾
[26:35.600 --> 26:37.040] 好像是会跳到行首
[26:37.040 --> 26:39.760] 我一般按control e再按回车
[26:39.760 --> 26:42.320] 就是开始在一行输入中间的时候
[26:42.320 --> 26:43.439] 按control e再按回车
[26:43.439 --> 26:44.560] 然后接着输入下一行
[26:44.560 --> 26:46.399] 就经常卡到
[26:46.399 --> 26:49.439] 把当前这一行变成了下一行
[26:49.439 --> 26:50.639] 就比较烦
[26:50.639 --> 26:54.800] 然后我当时跟语雀的那个同事说了一下
[26:54.800 --> 26:58.000] 然后语雀的同事把我转给了另一个
[26:58.000 --> 27:00.959] 就是语雀的一个负责的同事
[27:00.959 --> 27:02.240] 然后我跟他说了这个bug
[27:02.240 --> 27:04.000] 他说我这边不能复现
[27:04.000 --> 27:05.920] 我说是吗
[27:05.920 --> 27:08.560] 我这边用的出现的频率这么高
[27:08.560 --> 27:09.760] 你这边为什么不能复现
[27:09.760 --> 27:11.200] 我给他录了一个视频
[27:11.200 --> 27:14.960] 就是因为那个视频虽然是他看不到我的键盘
[27:14.960 --> 27:16.560] 但是他很容易发现
[27:16.560 --> 27:17.920] 就是说如果没有bug的话
[27:17.920 --> 27:19.520] 这个操作是做不出来了
[27:19.520 --> 27:21.440] 看视频的时候我还是复现不了
[27:21.440 --> 27:23.680] 你是不是在什么什么办公
[27:23.680 --> 27:24.320] 我说是
[27:24.320 --> 27:25.280] 他说我来找你
[27:25.280 --> 27:27.040] 然后他就带着电脑来找我
[27:27.040 --> 27:28.560] 然后我就去找他
[27:28.560 --> 27:30.320] 我给他现场演示
[27:30.320 --> 27:32.320] 就是打一行字跳到中间
[27:32.320 --> 27:33.520] 然后按control e回车
[27:33.520 --> 27:34.800] 你看bug出发了
[27:34.800 --> 27:36.080] 他说我来试一遍
[27:36.080 --> 27:38.320] 他还是不能复现
[27:38.320 --> 27:41.520] 就是我在他眼前我能复现
[27:41.520 --> 27:43.040] 但是他还是不能复现
[27:43.040 --> 27:44.720] 然后我说会不会是电脑的问题
[27:44.720 --> 27:46.320] 会不会是chrome版本的问题
[27:46.320 --> 27:48.080] 要不然我直接在你的环境敲一下
[27:48.080 --> 27:49.680] 我用他的电脑
[27:49.680 --> 27:51.600] 然后又复现了一遍
[27:51.600 --> 27:53.520] 就是百分之百能复现了几乎是
[27:53.520 --> 27:55.280] 他还是不行
[27:55.280 --> 27:56.240] 他敲一遍不行
[27:56.240 --> 27:57.200] 我敲一遍就行
[27:57.200 --> 27:58.160] 就很奇怪
[27:58.160 --> 27:59.600] 然后在我的电脑上
[27:59.600 --> 28:00.720] 他用我的电脑
[28:00.720 --> 28:02.639] 他也不会触发这个bug
[28:02.640 --> 28:03.920] 但是我总是会触发
[28:03.920 --> 28:07.120] 就是说这跟电脑没关系
[28:07.120 --> 28:08.800] 感觉就是跟人有关系
[28:08.800 --> 28:11.360] 我总是会遇到这个bug
[28:11.360 --> 28:12.240] 但是他不会遇到
[28:12.240 --> 28:13.520] 然后他就让我
[28:13.520 --> 28:15.440] 就是慢慢的敲
[28:15.440 --> 28:17.120] 就是给他看一下
[28:17.120 --> 28:18.240] 到底我是怎么按的
[28:18.240 --> 28:19.760] 然后我就慢慢的敲
[28:19.760 --> 28:21.200] 先打字
[28:21.200 --> 28:22.960] 然后按control e按完了
[28:22.960 --> 28:23.600] 按回车
[28:23.600 --> 28:25.680] 然后我也复现不了了
[28:25.680 --> 28:28.240] 然后我再打快点又能复现了
[28:28.240 --> 28:30.000] 我打慢一点又复现不了了
[28:30.000 --> 28:32.080] 最后就发现
[28:32.080 --> 28:33.760] 就是我们一遍一遍的试
[28:33.760 --> 28:34.639] 最后发现
[28:34.639 --> 28:36.240] 就是我按的快的时候
[28:36.240 --> 28:37.600] 其实我按键的习惯
[28:37.600 --> 28:39.760] 是跟按的慢的时候是不一样的
[28:39.760 --> 28:41.040] 就是按control e的时候
[28:41.040 --> 28:43.600] 我习惯control按下去
[28:43.600 --> 28:44.240] e按下去
[28:44.240 --> 28:45.120] 然后control松开
[28:45.120 --> 28:45.760] e松开
[28:45.760 --> 28:47.439] 就跟一个
[28:47.439 --> 28:51.760] 就是像是波浪的那种
[28:51.760 --> 28:53.040] 那个左手像是
[28:53.040 --> 28:54.480] 就是按下control按下e
[28:54.480 --> 28:56.000] 然后松开control松开e
[28:56.000 --> 28:57.679] 这种
[28:57.679 --> 28:59.199] 但是它是按住control
[28:59.199 --> 29:00.240] 然后按一下e
[29:00.240 --> 29:01.280] 就是按住了control
[29:01.280 --> 29:03.840] 按一下e松开e松开control
[29:03.840 --> 29:06.399] 所以说就是这么一个按键的区别
[29:06.399 --> 29:08.320] 就会导致这个bug
[29:08.320 --> 29:09.200] 有的时候可以复现
[29:09.200 --> 29:10.240] 有的时候不能复现
[29:10.240 --> 29:11.520] 就非常神奇
[29:11.520 --> 29:15.600] 需要一个记录敲键盘的那个工具
[29:15.600 --> 29:16.639] 然后就复现
[29:16.639 --> 29:19.840] 对有可能可以有帮助
[29:19.840 --> 29:22.000] 这也说明其实我们debug的时候
[29:22.000 --> 29:26.240] 万能的思路就是我们debug要搞一个最小能复现的case
[29:26.240 --> 29:28.639] 但有的时候这个case是比较难找的
[29:28.639 --> 29:29.680] 因为之前有人跟我说过
[29:29.680 --> 29:30.960] 如果一个bug你能复现
[29:30.960 --> 29:33.520] 说明你已经解决了80%
[29:33.520 --> 29:38.640] 但是一个比较有效的找能复现的方式就是
[29:38.640 --> 29:42.480] 你先用遇到bug的那个场景
[29:42.480 --> 29:45.040] 就是说你先确定怎么能复现那个场景
[29:45.040 --> 29:47.600] 最好是能100%复现
[29:47.600 --> 29:51.440] 然后一步一步的去减少它的影响的因素
[29:51.440 --> 29:53.760] 比如像http的话
[29:53.760 --> 29:57.200] 你就一步一步的把中间经过的环节试图把它拿掉
[29:57.200 --> 30:00.400] 然后看一下到底是加上了什么有问题没加什么有问题
[30:00.400 --> 30:04.240] 这样最终可以找出来一个最小的case
[30:04.240 --> 30:06.160] 然后再去研究这个case
[30:06.160 --> 30:08.400] 有时候这个还是非常难的
[30:08.400 --> 30:10.640] 去一些线上的系统
[30:10.640 --> 30:11.920] 对对
[30:11.920 --> 30:14.480] 尤其是在像沈明沙刚刚提到的
[30:14.480 --> 30:16.800] 跟网络有关或者跟并发有关
[30:16.800 --> 30:18.320] 跟那些竞争条件有关
[30:18.320 --> 30:19.840] 就是你找到一个
[30:19.840 --> 30:23.440] 你把这个case能100%的复现都比较困难
[30:23.440 --> 30:24.720] 其实刚才说那个
[30:24.720 --> 30:26.240] 听他说那个说的挺好的
[30:26.240 --> 30:28.240] 就是如果能够100%复现
[30:28.240 --> 30:31.440] 那基本就把握100%解决了
[30:31.440 --> 30:34.400] 刚才说的这个方法也是很正确的
[30:34.400 --> 30:35.920] 不断的缩减问题
[30:35.920 --> 30:37.840] 就是以前我们遇到过一个
[30:37.840 --> 30:41.280] 是我们的radius cluster在容器里面跑
[30:41.280 --> 30:44.080] 然后总是遇到性能问题
[30:44.080 --> 30:46.720] 对我们去发请求去测
[30:46.720 --> 30:48.720] 去记录latency统计
[30:48.720 --> 30:52.080] 发现latency总是跑一会儿就突然冒高
[30:52.080 --> 30:53.200] 然后跑一会儿又冒高
[30:53.200 --> 30:54.640] 开始是几位同事去看
[30:54.640 --> 30:56.160] 一直没有什么好的办法去做
[30:56.160 --> 30:58.240] 好了这里第一个drama的事情是
[30:58.240 --> 30:59.680] 他们的测试办法有问题
[30:59.680 --> 31:00.960] 他们用python去测的
[31:00.960 --> 31:03.600] python去测性能是不准确的
[31:03.600 --> 31:06.080] 因为python自己就有性能的监测
[31:06.080 --> 31:07.680] 对这个特别drama
[31:07.680 --> 31:10.400] 他们一直用python去作为客户端发请求
[31:10.400 --> 31:12.000] 然后去统计latency
[31:12.000 --> 31:14.320] 但实际上python就算没有任何问题
[31:14.320 --> 31:17.760] python测出来的性能都是有性能监测的
[31:17.760 --> 31:19.840] 所以说python不适合作为一个
[31:19.840 --> 31:21.680] 性能测试的客户端去做
[31:21.680 --> 31:23.680] 但就算排除了python的问题
[31:23.680 --> 31:26.720] 我们的容器里面的服务确实有性能的监测
[31:26.720 --> 31:30.320] 这个问题其实最后的解决方法是和姓涛一样的
[31:30.320 --> 31:31.280] 说的一样的
[31:31.280 --> 31:33.360] 就是既然线上的容器有问题
[31:33.360 --> 31:35.840] 而线下的裸跑的服务没问题
[31:35.840 --> 31:40.160] 我们先把线上容器一步步缩少它的范围
[31:40.160 --> 31:41.280] 比如线上是一个集群
[31:41.280 --> 31:43.680] 是个5节点的cluster
[31:43.680 --> 31:45.360] VS cluster集群的容器点
[31:45.360 --> 31:47.040] 我们先把它缩到一个节点上
[31:47.040 --> 31:51.200] 一个单节点单容器的服务能不能浮现
[31:51.200 --> 31:51.840] 如果能的话
[31:51.840 --> 31:53.760] 那我们就缩少了问题成5倍了
[31:53.760 --> 31:55.280] 我们就缩少了5倍的问题
[31:55.280 --> 31:58.080] 结果发现缩少5倍就依然能发现
[31:58.080 --> 31:58.720] 那就太好了
[31:58.720 --> 32:00.320] 我们就在一个节点上搞
[32:00.320 --> 32:02.639] 我们在线上的节点上
[32:02.639 --> 32:06.639] 在相同的节点上裸起一个相同的radius进程
[32:06.639 --> 32:08.080] 唯一的不同就是一个在容器里
[32:08.080 --> 32:09.040] 一个不在容器
[32:09.040 --> 32:11.360] 再来对比它们的行为是否不一样
[32:11.360 --> 32:12.639] 然后发现果然不一样
[32:12.639 --> 32:13.840] 容器里依然有问题
[32:13.840 --> 32:15.120] 然后裸跑了没问题
[32:15.120 --> 32:16.800] 接下来我们就两边逼近就好了
[32:16.800 --> 32:21.760] 我们一点一点的去看它两个进程有什么区别
[32:21.760 --> 32:23.760] 比如说容器就那几套嘛
[32:23.760 --> 32:26.240] Namespace 网络SDN
[32:26.240 --> 32:28.160] 还有Cgroup 还有Capability
[32:28.160 --> 32:30.160] 这一套一套的往手
[32:30.160 --> 32:32.320] 你不管是让那个裸跑的进程
[32:32.320 --> 32:34.240] 你说往上加这些特性
[32:34.240 --> 32:36.160] 还是在容器去减这些特性
[32:36.160 --> 32:37.120] 都是能够做到的
[32:37.120 --> 32:39.520] 这样一点一点的去增减
[32:39.520 --> 32:42.240] 去逼近两个两头的服务
[32:42.240 --> 32:45.600] 然后最后发现是Cgroup CPU-SIT
[32:45.600 --> 32:47.760] CPU缩透的问题对吧
[32:47.760 --> 32:49.280] 对对对是的
[32:49.280 --> 32:51.520] 但是重点不是结论
[32:51.520 --> 32:53.440] 我一直觉得第八个
[32:53.440 --> 32:55.600] 刚才信涛也说了一个经验问题
[32:55.600 --> 32:57.040] 我觉得经验当然是很好的
[32:57.040 --> 33:01.200] 经验最好的一点就是在面对问题的时候
[33:01.200 --> 33:03.360] 能够让你走捷径
[33:03.360 --> 33:04.160] 对shortcut
[33:04.160 --> 33:05.920] 能够让你一步就走到这个地方
[33:05.920 --> 33:10.480] 但其实我并不欣赏这一点
[33:10.480 --> 33:12.240] 因为问题是无穷无尽的
[33:12.240 --> 33:15.200] 人在学习更多新东西的时候
[33:15.200 --> 33:16.879] 总是会面对未知的问题
[33:16.879 --> 33:18.560] 所以我更看重的是
[33:18.560 --> 33:20.639] 你如何去分析一个未知的问题
[33:20.640 --> 33:23.520] 如何去找到正确的路径去做这个事情
[33:23.520 --> 33:26.080] 而不是一个捷径
[33:26.080 --> 33:27.680] 所以刚才说的
[33:27.680 --> 33:28.960] 刚才的VS cluster的问题
[33:28.960 --> 33:31.600] 最后是CPU-SIT造成的CPU-THROTTLE
[33:31.600 --> 33:32.880] 这个结论当然很好了
[33:32.880 --> 33:34.720] 以后我们知道这问题
[33:34.720 --> 33:35.680] 但问题是
[33:35.680 --> 33:37.520] 但我更想分享的是
[33:37.520 --> 33:38.720] 我们在解决这个问题的时候
[33:38.720 --> 33:40.000] 中间的做法
[33:40.000 --> 33:40.800] 中间的思路
[33:40.800 --> 33:42.400] 我们去缩减问题规模
[33:42.400 --> 33:44.960] 我们去在原地相同的地点
[33:44.960 --> 33:47.520] 旁路建立了一个正确的服务
[33:47.520 --> 33:50.560] 所以我们就有了一个正确和不正确的服务
[33:50.560 --> 33:52.399] 然后把两个服务去逼近他们的状态
[33:52.399 --> 33:55.360] 看看到底是哪一个状态造成了这个问题
[33:55.360 --> 33:58.560] 这样就能一点点的去比
[33:58.560 --> 34:02.720] 我觉得这个是希望听众能够去思考的
[34:02.720 --> 34:04.480] 而不是去就记下来说
[34:04.480 --> 34:06.879] CPU-GROOVE可能会造成这个问题
[34:06.879 --> 34:08.480] 这个结论是没有问题的
[34:08.480 --> 34:10.799] 但是这个分析问题的思路
[34:10.799 --> 34:12.799] 是我们应该去反复去思考的
[34:12.799 --> 34:15.600] 因为在以后遇到新的更多困难问题
[34:15.600 --> 34:17.440] 能够去做
[34:17.440 --> 34:18.480] 对 是的
[34:18.480 --> 34:22.560] 我其实遇到类似问题也和你一样
[34:22.560 --> 34:26.560] 然后当时是我们就当时是突然发现有个服务
[34:26.560 --> 34:27.760] 在容器环境下
[34:27.760 --> 34:30.480] 就突然一下那个就监控上面99
[34:30.480 --> 34:31.360] PT99
[34:31.360 --> 34:33.920] 然后一下那个就有毛刺
[34:33.920 --> 34:36.560] 就是那个一下会升高有毛刺
[34:36.560 --> 34:38.480] 对 然后又快速恢复
[34:38.480 --> 34:42.000] 当时我最开始怀疑是网络问题
[34:42.000 --> 34:44.240] 因为这种东西就可能说网络不稳定
[34:44.240 --> 34:45.840] 丢包重传之类的
[34:45.840 --> 34:46.240] 对吧
[34:46.240 --> 34:47.600] 就第一反应可能说
[34:47.600 --> 34:50.319] 就是说你跟RTT有关的可能就丢包反应
[34:50.319 --> 34:53.520] 然后那么然后我当时就
[34:53.520 --> 34:55.520] 因为你这个时候你这个问题
[34:55.520 --> 35:00.000] 你是从你去调用方看你的那个请求的那个就是失言
[35:00.000 --> 35:01.360] 实际上是没有什么用的
[35:01.360 --> 35:02.400] 然后对
[35:02.400 --> 35:04.880] 然后那么实际上我当时就做了
[35:04.880 --> 35:07.839] 就是首先是优先就排除他网络问题
[35:07.839 --> 35:12.160] 我去搞了一个就基于当时基于eBPF搞了有东西
[35:12.160 --> 35:13.520] 去监控了他网
[35:13.520 --> 35:15.600] 就是说是因为网就是来回
[35:15.600 --> 35:17.759] 就是双向的就是说是看看他
[35:17.759 --> 35:19.360] 因为我们是支持SACK的
[35:19.360 --> 35:23.120] 然后我看一下他的就是说丢包和重传的情况
[35:23.120 --> 35:23.839] 就是对
[35:23.839 --> 35:25.920] 然后因为那个4.15之后
[35:25.920 --> 35:27.920] 他的trace point也支持那个东西
[35:27.920 --> 35:30.080] 然后我去监控他丢包重传
[35:30.080 --> 35:31.920] 发现网络实际上是稳定的
[35:31.920 --> 35:34.640] 就是说他的那个就时间是对不上的
[35:34.640 --> 35:36.799] 然后后面我才开始一步步怀疑
[35:36.799 --> 35:38.240] 就是就缩小范围
[35:38.240 --> 35:41.839] 怀疑说这个地方是不是就早现场底下
[35:41.840 --> 35:45.680] 我然后后面去单独起了Docker容器也能复现这个情况
[35:45.680 --> 35:48.240] 然后那么就是说是在怀疑开始
[35:48.240 --> 35:52.080] 然后最后是确定到CPU SOLT的解决的这个问题
[35:52.080 --> 35:55.440] 对我觉得这还是跟Gray和新涛说的一样
[35:55.440 --> 36:01.520] 就是说你先就波斯抽捡就一下就不要想太困难
[36:01.520 --> 36:05.760] 然后就先从最开始你可以先就去确定一个方向
[36:05.760 --> 36:07.680] 就是说建立假设否定假设
[36:07.680 --> 36:09.680] 然后最终找到最终的Roller Course
[36:09.680 --> 36:14.160] 这个说到这个新涛上次你那个虽然我知道好像剧透了
[36:14.160 --> 36:15.440] 你准备接下来说的
[36:15.440 --> 36:20.240] 上次那个问题我先简单说一下我的想法吧
[36:20.240 --> 36:22.160] 你还记得我和你讨论的时候
[36:22.160 --> 36:26.640] 和你说过这个逼近的想法
[36:26.640 --> 36:28.879] 但我们没有做下去
[36:28.879 --> 36:32.160] 对当时的情况是说你在你线上容器部署的服务
[36:32.160 --> 36:34.160] 去HP是有问题的对吧
[36:34.160 --> 36:37.120] 但是你说你在本地是没问题的对吧
[36:37.120 --> 36:45.600] 对当时我就说如果把本地的服务运行方式搬到线上去看有没有问题
[36:45.600 --> 36:49.279] 如果当时这么做的话会发现搬上去是没有问题的对吧
[36:49.279 --> 36:52.000] 因为本质问题是你运行的进程数还是线程数
[36:52.000 --> 36:56.319] 对如果你做这一步你就有两个进程
[36:56.319 --> 36:58.960] 一个进程是有问题一个进程没问题
[36:58.960 --> 37:00.560] 他们之间有一些小小的差别
[37:00.560 --> 37:01.759] 但他们都在容器里对吧
[37:01.759 --> 37:05.440] 接下来你只要去让这两个进程去状态逼近好了
[37:05.440 --> 37:07.680] 他们是否有什么配置不一样
[37:07.680 --> 37:09.840] 是否有什么不一样
[37:09.840 --> 37:11.840] 因为在容器里面其实大部分都一样了
[37:11.840 --> 37:13.520] 但是他们有一些微小的区别
[37:13.520 --> 37:16.080] 你让这两个服务去相互逼近一下
[37:16.080 --> 37:19.600] 你就会知道哪一个配置造成了这个问题
[37:19.600 --> 37:22.720] 接下来我就可以知道这个配置到底造成了
[37:22.720 --> 37:26.880] 这个配置的什么造成了什么变化才导致了这个问题
[37:26.880 --> 37:30.640] 其实这种问题都是
[37:30.640 --> 37:32.960] 是个笨办法但是是有效的
[37:32.960 --> 37:34.240] 很笨但很有效
[37:34.240 --> 37:39.200] 就是说我手上有一个几乎可以100%复现的一个case一个进程
[37:39.200 --> 37:44.640] 然后同时我可以简单的起一个没有问题的进程
[37:44.640 --> 37:45.759] 没有问题的case
[37:45.759 --> 37:48.720] 我只要让这两个进程相互逼近一下
[37:48.720 --> 37:50.479] 虽然逼近的过程会很痛苦
[37:50.479 --> 37:51.919] 你需要一点点的逼近
[37:51.919 --> 37:55.200] 每次逼近一点点可能不是问题
[37:55.200 --> 37:58.080] 甚至最后你知道是哪一项配置造成问题
[37:58.080 --> 37:59.600] 你也得仔细去看代码
[37:59.600 --> 38:02.080] 它是一个很痛苦很漫长的过程
[38:02.080 --> 38:04.960] 但是我可以很肯定说这个过程是能够找到问题的
[38:04.960 --> 38:07.440] 因为我用这个笨办法找到了很多很多的问题
[38:07.440 --> 38:09.440] 所以说对
[38:09.440 --> 38:14.880] 所以我就说如果一个问题能够100%复现的话
[38:14.880 --> 38:16.799] 我觉得几乎就可以肯定能够解决了
[38:16.799 --> 38:18.720] 因为我总是能够通过逼近的办法
[38:18.720 --> 38:21.360] 去二分一个问题能缩小规模
[38:21.360 --> 38:23.200] 或者是通过删减代码也好
[38:23.200 --> 38:24.480] 对这是最更简单的办法
[38:24.480 --> 38:26.640] 你如果没有一个正确的服务去对比
[38:26.640 --> 38:28.160] 那你就在原服务上面
[38:28.160 --> 38:30.319] 你去改它的原代码
[38:30.320 --> 38:34.640] 你把它那些你认为没有影响的代码给它删
[38:34.640 --> 38:37.600] 删了之后重新编译重新扔上去重新跑起来
[38:37.600 --> 38:40.160] 你看新的二进制有没有相同的问题
[38:40.160 --> 38:43.280] 或者说你把问题规模一点点的缩减
[38:43.280 --> 38:46.080] 缩减到直到你删那一行代码这问题就不存在了
[38:46.080 --> 38:48.640] 加上那一行代码问题又回来了
[38:48.640 --> 38:50.160] 那你就知道是那一行代码的问题
[38:50.160 --> 38:52.720] 接下来我们就看这一行代码做了什么事情
[38:52.720 --> 38:56.560] 这个办法很笨但是很花时间而且很消耗精力
[38:56.560 --> 38:59.520] 我自己做的时候经常会觉得好累
[38:59.520 --> 39:01.120] 好晚我好想睡觉
[39:01.120 --> 39:04.640] 但是它很有效它能够让你找到问题
[39:04.640 --> 39:09.120] 所以说蔚蓝心理有正确的办法之后
[39:09.120 --> 39:12.240] 大家还是要希望听众能够克服蔚蓝心理
[39:12.240 --> 39:15.520] 能够去做下去找到正确的办法去做下去
[39:15.520 --> 39:18.960] 就是很好的
[39:18.960 --> 39:22.560] 其实debug的时候中间的心理状态情绪也是蛮重要的
[39:22.560 --> 39:24.320] 最后经常会自己放弃了
[39:24.320 --> 39:27.280] 对实际上最后再去看问题
[39:27.280 --> 39:29.840] 其实只差一点点就能找到
[39:29.840 --> 39:32.080] 这是很正常的
[39:32.080 --> 39:35.200] 说到这个问题我就简单的介绍一下
[39:35.200 --> 39:38.000] 当时跟Gorilla Debug的这个问题
[39:38.000 --> 39:39.120] 其实比较有意思
[39:39.120 --> 39:41.360] 我在博客上介绍过
[39:41.360 --> 39:43.920] 回头我把链接也贴到show notes里面
[39:43.920 --> 39:46.480] 就是简单来说我当时写了一个服务
[39:46.480 --> 39:49.040] 就是它提供了一个http的接口
[39:49.040 --> 39:51.600] 然后用户在访问这个接口的时候
[39:51.600 --> 39:53.520] 告诉我一个IP一个端口
[39:53.520 --> 39:54.960] 然后我告诉用户
[39:54.960 --> 40:00.080] 当前的这个服务到IP端口的延迟是多少
[40:00.080 --> 40:01.120] 大家可以理解
[40:01.120 --> 40:05.200] 就是说我提供一个检测延迟的服务TCP
[40:05.200 --> 40:11.120] 然后我的服务其实是用HPIN3来实现的
[40:11.120 --> 40:16.400] HPIN3其实就是发SYN包到目标上去
[40:16.400 --> 40:17.760] 然后看这个延迟是多少
[40:17.760 --> 40:20.000] 然后当时的现象就是
[40:20.000 --> 40:21.840] 我在本地测试OK
[40:21.840 --> 40:23.520] 但是我把它部署到线上的话
[40:23.520 --> 40:26.080] 就出问题了
[40:26.080 --> 40:29.280] 然后自己找了很长时间没找到
[40:29.280 --> 40:32.240] 怀疑是容器对网络做了一些限制
[40:32.240 --> 40:39.920] 怀疑是可能是乱七八糟的一些问题
[40:39.920 --> 40:40.800] 反正都怀疑过
[40:40.800 --> 40:42.720] 当时也是方法非常不对
[40:42.720 --> 40:44.960] 就是自己去瞎怀疑一些问题
[40:44.960 --> 40:46.320] 然后去验证发现不是
[40:46.320 --> 40:49.120] 而不是说一步步的去逼近这个问题
[40:49.120 --> 40:50.560] 然后当时找了Grey
[40:50.560 --> 40:52.160] Grey跟我说你就删代码
[40:52.160 --> 40:52.960] 一半一半的删
[40:52.960 --> 40:54.240] 我觉得太麻烦了
[40:54.240 --> 40:55.920] 我这个写了这么多代码
[40:55.920 --> 40:56.880] 我要把它删
[40:56.880 --> 41:00.000] 每删一次我要重新编译对吧
[41:00.000 --> 41:01.920] 然后走发布把它部署上去
[41:01.920 --> 41:02.560] 然后测一下
[41:02.560 --> 41:05.280] 就每次部署都比较花时间
[41:05.280 --> 41:08.960] 然后我就
[41:08.960 --> 41:10.720] 我当时又问了另一个人
[41:10.720 --> 41:11.920] 就是另一个人比较有经验
[41:11.920 --> 41:14.480] 然后他就告诉我可能是SIGNAL被block了
[41:14.480 --> 41:15.520] 你去看一眼
[41:15.520 --> 41:20.480] 然后发现确实SIGNAL被block了
[41:20.480 --> 41:23.680] 就是HPins3这个工具它会用到一个SIGNAL
[41:23.680 --> 41:25.280] 来让自己正常工作
[41:25.280 --> 41:26.880] 如果那个SIGNAL被block的话
[41:26.880 --> 41:30.560] 它永远收不到一个自己发出去的SIGNAL
[41:30.560 --> 41:33.280] 这样的话它这个进程就结束不了
[41:33.280 --> 41:35.200] 跟我们当时现象也是一样的
[41:35.200 --> 41:38.640] 然后唯一的不同就是
[41:38.640 --> 41:40.000] 为什么线上出问题
[41:40.000 --> 41:41.280] 线下我自己没有问题
[41:41.280 --> 41:42.880] 因为线下我跑的是
[41:42.880 --> 41:47.040] Jango的Python Managed Run Server
[41:47.040 --> 41:48.320] 是一个debug环境
[41:48.320 --> 41:50.880] 线上是用UWSGI
[41:50.880 --> 41:53.680] UWSGI服务器
[41:53.680 --> 41:56.880] 然后UWSGI在超过一个线程工作的时候
[41:56.880 --> 42:00.880] 其他的线程都会把所有的信号给block掉
[42:00.880 --> 42:02.960] 就是这么一个环境的区别
[42:02.960 --> 42:04.240] 所以现在来看
[42:04.240 --> 42:05.600] 那位同事比较有经验
[42:05.600 --> 42:07.200] 他一看这个问题
[42:07.200 --> 42:09.520] 他就知道去看那个SIGNAL
[42:09.520 --> 42:12.480] 所以确实可能是经验是一个捷径
[42:12.480 --> 42:14.320] 但是假如说现在来看
[42:14.320 --> 42:15.760] 我们当时没有那个经验的话
[42:15.760 --> 42:17.280] 我们就因为已经有一个
[42:17.280 --> 42:19.200] 100%可以复现的环境了
[42:19.200 --> 42:22.240] 我们其实可以去一步一步的
[42:22.240 --> 42:24.240] 再把线下的环境
[42:24.240 --> 42:25.440] 跟线上的环境去逼近
[42:25.440 --> 42:27.200] 看一下到底是加了哪一行配置
[42:27.200 --> 42:29.680] 才导致了问题的出现
[42:29.680 --> 42:32.080] 其实最终也是能发现这个问题的
[42:32.080 --> 42:33.440] 我们其实当时也是了
[42:33.440 --> 42:35.600] 在线上跑那个Python Managed
[42:35.600 --> 42:38.240] .py Run Server的话是正常的
[42:38.240 --> 42:39.840] 但是奇怪的是在线下
[42:39.840 --> 42:42.720] 我在我的笔记本上用UWSGI来起来
[42:42.720 --> 42:44.320] 它也是正常的
[42:44.320 --> 42:45.440] 就是这个地方
[42:45.440 --> 42:47.680] 我感觉要搜索的区间比较大了
[42:47.680 --> 42:48.960] 所以自己没有搞下去
[42:48.960 --> 42:50.560] 后来也是发现
[42:50.560 --> 42:51.840] 因为我在我的笔记本上
[42:51.840 --> 42:53.760] 没有完全用线上的环境
[42:53.760 --> 42:55.040] 我虽然起了UWSGI
[42:55.040 --> 42:56.400] 但是我只用了一个线上
[42:56.400 --> 42:59.040] 就用UWSGI的默认配置
[42:59.040 --> 43:01.200] 所以说现在回想一下
[43:01.200 --> 43:02.720] 应该用线上的
[43:02.720 --> 43:05.600] 就是除了改改日志的路径
[43:05.600 --> 43:07.840] 应该用完全用线上的配置来模拟的话
[43:07.840 --> 43:09.600] 会更快的找到这个问题
[43:09.600 --> 43:11.040] 会少花一点时间
[43:11.040 --> 43:13.360] 说到我们去逼近这么一个环境
[43:13.360 --> 43:14.880] 其实我们一个方法是
[43:14.880 --> 43:17.120] 删现有的代码
[43:17.120 --> 43:18.160] 其实另一个方法是
[43:18.160 --> 43:20.000] 我想推荐一个工具
[43:20.000 --> 43:21.920] 是Git bset
[43:21.920 --> 43:23.600] 就是我不知道念的对不对
[43:23.600 --> 43:24.480] 是那个二分查找
[43:24.480 --> 43:25.120] 对
[43:25.120 --> 43:27.280] 就是我们一个删代码的方法
[43:27.280 --> 43:28.320] 是删现有的代码
[43:28.320 --> 43:29.600] 另一个是删历史的代码
[43:29.600 --> 43:30.720] 就怎么说呢
[43:30.720 --> 43:33.120] 我们的bug有可能是在历史的某一个
[43:33.120 --> 43:35.120] 某一个commit来引入的
[43:35.120 --> 43:36.800] 你发现现在代码有问题
[43:36.800 --> 43:38.560] 你不知道历史哪一个commit是
[43:38.560 --> 43:40.160] 引入的话
[43:40.160 --> 43:43.680] 你可以用那个Git的二分搜索
[43:43.680 --> 43:47.279] 就是说你告诉Git一个好的commit
[43:47.279 --> 43:48.640] 有可能是之前的
[43:48.640 --> 43:49.839] 很久之前的一个commit
[43:49.839 --> 43:52.000] 然后你告诉Git一个坏的commit
[43:52.000 --> 43:55.520] 然后Git就会开始帮你做二分查找
[43:55.520 --> 43:56.319] 不是帮你
[43:56.319 --> 43:57.440] 就是跟你一起做
[43:57.440 --> 43:59.839] Git会自动给你切换到一个commit
[43:59.839 --> 44:02.240] 然后你去验证这个commit是否是OK的
[44:02.240 --> 44:03.680] 如果OK的话
[44:03.680 --> 44:06.000] 你就告诉Git这个commit是OK的
[44:06.000 --> 44:07.040] 如果不是OK的话
[44:07.040 --> 44:08.160] 你告诉这个Git
[44:08.160 --> 44:09.839] 这个commit已经坏了
[44:09.839 --> 44:12.160] 然后Git会自动帮你用二分查找
[44:12.160 --> 44:14.000] 切换到他认为下一个
[44:14.000 --> 44:15.520] 你应该去验证的commit
[44:15.520 --> 44:17.279] 直到把这个搜索范围
[44:17.279 --> 44:21.839] 锁定到某一个commit的变更
[44:21.839 --> 44:25.279] 然后bug就是从这个commit开始引入的
[44:25.279 --> 44:27.040] 这个方法我经常用
[44:27.040 --> 44:28.000] 这样的话
[44:28.000 --> 44:30.240] 你可能不知道bug的根因是什么
[44:30.240 --> 44:32.960] 但是你看到那个Git commit的diff之后
[44:32.960 --> 44:33.920] 你就明白了
[44:33.920 --> 44:38.640] 但是你怎么知道是历史代码引入的bug
[44:38.640 --> 44:40.000] 而不是你现在代码引入
[44:40.000 --> 44:41.920] 你什么时候决定开始用这种方法
[44:41.920 --> 44:43.360] 决定的方法就是
[44:43.360 --> 44:46.080] 你现在的代码有一个bug对吧
[44:46.080 --> 44:47.520] 那你不确定
[44:47.520 --> 44:48.960] 你把它切换到上一个版本
[44:48.960 --> 44:50.560] 你看是不是同样有这个bug
[44:50.560 --> 44:52.320] 如果上一个版本也有的话
[44:52.320 --> 44:54.080] 你把它切换到再往前一个版本
[44:54.080 --> 44:56.000] 对吧
[44:56.000 --> 44:58.960] 它能工作的一种场景就是
[44:58.960 --> 45:01.920] 之前你找到了一个commit它是好的
[45:01.920 --> 45:03.440] 但是现在的commit它是坏的
[45:03.440 --> 45:05.760] 对其实我们在查问题的时候
[45:05.760 --> 45:07.840] 很多时候很多的bug
[45:07.840 --> 45:10.880] 其实是由配置变更
[45:10.880 --> 45:14.240] 或者是就业务代码的东西进来
[45:14.240 --> 45:16.640] 这个时候其实就首先定位
[45:16.640 --> 45:20.800] 当然首先先直选
[45:20.800 --> 45:25.920] 然后定位就说是具体是在哪一组commit里面引进来的
[45:25.920 --> 45:29.200] 然后最后可能是更有利于去查rot cause
[45:29.200 --> 45:32.640] 不然的话就还是有一点一头乱麻
[45:32.640 --> 45:34.880] 因为我现在遇到了一个case
[45:34.880 --> 45:37.280] 然后我不知道你们有没有什么比较好的方法debug
[45:37.280 --> 45:43.040] 就是就我觉得之前说的可能更多的是一种
[45:43.040 --> 45:45.280] 怎么去debug incremental change
[45:45.280 --> 45:46.560] 比如说你有一个代码库
[45:46.560 --> 45:48.320] 然后你在什么加了一个feature
[45:48.320 --> 45:50.720] 或者是做了一些什么refactoring
[45:50.720 --> 45:53.200] 然后怎么去debug
[45:53.200 --> 45:55.440] 然后我现在遇到一个case是
[45:55.440 --> 46:02.240] 就是我们组相当于是要引入一个全新的framework
[46:02.240 --> 46:03.760] 你可以理解为framework吧
[46:03.760 --> 46:06.160] 去替代原来用的一个framework
[46:06.160 --> 46:08.720] 然后相当于我们构建了一套
[46:08.720 --> 46:11.279] 就像因为我们把原来包了一层
[46:11.279 --> 46:12.560] 你可以这么理解
[46:12.560 --> 46:15.120] 就是有两套功能上一样的代码
[46:15.120 --> 46:17.040] 但是用的是不同framework来跑的
[46:17.040 --> 46:19.359] 然后现在新的这个
[46:19.359 --> 46:23.040] 它的就发现有时候它的latency会有一些spike
[46:23.040 --> 46:25.600] 然后再debug这个事情
[46:25.600 --> 46:30.720] 然后它就我感觉就比较难说去通过那种
[46:30.720 --> 46:33.680] 删减什么的方式来做
[46:33.680 --> 46:36.879] 因为你可能因为你这两个本来它就是完全不一样
[46:36.879 --> 46:41.359] 所以你然后我也不知道应该就是去删什么
[46:41.359 --> 46:43.680] 并且它其中涉及到很多
[46:43.680 --> 46:46.799] 就跑了很多模块根本就不是我们组掌握的
[46:46.799 --> 46:49.040] 就相当于我们只是做这样一个migration
[46:49.040 --> 46:52.799] 但是里面有很多的业务是其他组负责的
[46:52.799 --> 46:55.759] 所以我现在的思路是想
[46:55.759 --> 47:02.480] 就是说我们有一个这种能够在类似于local的环境
[47:02.480 --> 47:07.920] 去做一个这种AB test的这种环境
[47:07.920 --> 47:11.440] 然后就是想看一下在本地能不能去服务
[47:11.440 --> 47:15.040] 因为我之前其实是跑单独的low test
[47:15.040 --> 47:16.320] 我没有发现有什么问题
[47:16.320 --> 47:24.240] 但是可能当时就是没有在同样的环境去跑
[47:24.240 --> 47:27.840] 然后导致我现在已经把那个change去
[47:27.840 --> 47:29.200] 放到了experiment上面
[47:29.200 --> 47:30.960] 然后我发现它的latency升高了
[47:30.960 --> 47:36.240] 所以可能应该就要在一个同样的环境去同时跑两组代码
[47:36.240 --> 47:40.400] 然后来看一下它会不会还是有这样的一个延迟的差距
[47:40.400 --> 47:43.280] 就不知道你们有没有什么思路
[47:43.280 --> 47:45.680] 我也还不太确定
[47:45.680 --> 47:50.880] 你觉得是latency是整体的试验的升高还是只是一个毛刺
[47:50.880 --> 47:52.720] 它实际上不是毛刺
[47:52.720 --> 47:54.640] 就是它的变化非常大
[47:54.640 --> 47:56.960] 就是它小的时候可能差不多
[47:56.960 --> 47:58.880] 但是它大的时候就很大
[47:58.880 --> 48:01.040] 然后它会有涨落
[48:01.040 --> 48:05.280] 我甚至怀疑过是不是跟线上的一些load balancing有关
[48:05.280 --> 48:07.840] 但是我也现在还不太确定
[48:07.840 --> 48:09.920] 所以我想就是现在本地试一下
[48:09.920 --> 48:12.960] 我不太确定你这种框架
[48:12.960 --> 48:14.240] 因为如果是这种
[48:14.240 --> 48:16.560] 然后是不是就有些时候一下大了
[48:16.560 --> 48:18.320] 然后有些时候水位又会跌下去
[48:18.320 --> 48:19.360] 就是latency
[48:19.360 --> 48:20.640] 然后又会跌
[48:20.640 --> 48:24.080] 对可以这样理解
[48:24.080 --> 48:25.760] 就是那种波浪波谷波浪
[48:25.760 --> 48:27.680] 就是波谷那种波浪那种
[48:27.680 --> 48:29.279] 也没有特别波谷波浪
[48:29.279 --> 48:31.520] 可能一天里比如说有
[48:31.520 --> 48:34.319] 先是低然后再是高
[48:34.319 --> 48:35.359] 然后又会低下来
[48:35.359 --> 48:37.919] 高的时间大概可能会持续大概
[48:37.919 --> 48:40.480] 可能一天中的大部分时候
[48:40.480 --> 48:42.000] 对就是我怀疑它是跟
[48:42.000 --> 48:47.120] 就感觉是跟它的一个机器忙不忙有关
[48:47.120 --> 48:50.720] 然后就比如说
[48:50.720 --> 48:54.560] 假设就是我之前怀疑它是可能是load balancing的问题
[48:54.560 --> 48:57.120] 就是比如说是新的这个框架
[48:57.120 --> 48:58.400] load balancing没做好
[48:58.400 --> 49:00.319] 然后它会选择一些比较
[49:00.319 --> 49:03.520] 就是没有办法选择到那个load比较轻的一些job
[49:03.520 --> 49:06.720] 然后导致它就是一天中忙的时候
[49:06.720 --> 49:09.279] 所以它的latency就上升了
[49:09.279 --> 49:12.080] 然后这个是一种可能
[49:12.080 --> 49:15.040] 我自己的想法就是说对于这种的话
[49:15.040 --> 49:17.359] 首先来讲的话就是
[49:17.359 --> 49:19.920] 如果像比如说加拉西的话
[49:19.920 --> 49:22.080] 首先我会去查它的GC状态
[49:22.080 --> 49:23.120] 或是其他的
[49:23.120 --> 49:25.279] 因为如果说是整体的都是每天
[49:25.280 --> 49:27.280] ok好吧
[49:27.280 --> 49:30.400] 那我可能就是因为既然是这种整体的
[49:30.400 --> 49:31.200] 而且是规律的
[49:31.200 --> 49:34.080] 我觉得可能和具体的业务代码没什么太大关系
[49:34.080 --> 49:35.840] 我自己就可能会去
[49:35.840 --> 49:39.600] 首先看它的就上下游依赖的情况
[49:39.600 --> 49:43.280] 上下游依赖的那个食盐和其他的就包括丢包率
[49:43.280 --> 49:45.920] 你们谷歌肯定这方面的监控是全的
[49:45.920 --> 49:47.360] 就上下游的依赖率
[49:47.360 --> 49:49.120] 就是说是latency
[49:49.120 --> 49:51.120] 然后丢包率这些的情况
[49:51.120 --> 49:53.760] 然后再看机器上面的
[49:53.760 --> 49:55.200] 就是说是水位
[49:55.200 --> 49:58.000] 然后对列就是说是细粒度的指标
[49:58.000 --> 49:58.560] 这一些
[49:58.560 --> 50:00.960] 然后可能是这样的一些concern
[50:00.960 --> 50:03.280] 我自己的就是说是一些切入点
[50:03.280 --> 50:05.040] 可能是可以往这方面去切
[50:05.040 --> 50:08.640] 对其实还有个问题就是
[50:08.640 --> 50:11.520] 就是监控的这些也不是特别全
[50:11.520 --> 50:15.200] 就是因为是在一个新的
[50:15.200 --> 50:16.640] 就部署一些新的东西
[50:16.640 --> 50:19.280] 所以可能我是也想加一些
[50:19.280 --> 50:20.800] 对你说的是有道理
[50:20.800 --> 50:23.040] 那现在可能就不太全
[50:23.040 --> 50:26.240] 我觉得甩锅吧
[50:26.240 --> 50:31.600] 假如从监控上能找到一个跟你说的latency
[50:31.600 --> 50:33.200] 非常match的线的话
[50:33.200 --> 50:36.480] 应该就比较好弄了
[50:36.480 --> 50:42.000] 我们现在其实我也遇到一个跟你一模一样的问题
[50:42.000 --> 50:42.800] 还没有解决
[50:42.800 --> 50:44.080] 也持续了很长时间
[50:44.080 --> 50:48.320] 就是latency有的时候会突然有一个spike
[50:48.320 --> 50:50.960] 但是我们找不到这个spike到底跟什么有关
[50:50.960 --> 50:53.520] 你们是在容器里面的吗
[50:53.520 --> 50:57.360] 是物理机上的
[50:57.360 --> 51:04.000] 所以是这个问题可能比较难
[51:04.000 --> 51:06.800] 先区分是操作系统的锅还是应用的锅
[51:06.800 --> 51:08.880] 这个其实很好去做
[51:08.880 --> 51:12.880] 你只要去trace那几个socket的API
[51:12.880 --> 51:14.320] 什么receive send
[51:14.320 --> 51:15.680] 然后就这些东西
[51:15.680 --> 51:19.360] 你先看应用层的代码
[51:19.360 --> 51:24.720] 他send的这些字节是什么时候
[51:24.720 --> 51:28.960] 然后你看是application造成的这些spike
[51:28.960 --> 51:32.480] 还是说application都是很准点准时的
[51:32.480 --> 51:34.720] 把这些字节给发送给了内核
[51:34.720 --> 51:37.280] 但是内核处理这些字节由于别的原因
[51:37.280 --> 51:38.560] 内核造成的spike
[51:38.560 --> 51:43.440] 先把问题分到是application的锅还是操作系统的锅
[51:43.440 --> 51:46.400] 操作系统也会被别的application的影响
[51:46.400 --> 51:50.880] 先确认是application造成的还是操作系统的锅
[51:50.880 --> 51:51.840] 这个很好做
[51:51.840 --> 51:53.360] 你只要trace一下
[51:53.360 --> 51:57.920] 你自己手写的BCC都可以做
[51:57.920 --> 52:01.520] 只要统计一下应用层发送
[52:01.520 --> 52:04.560] 他调用socket的那几个API
[52:04.560 --> 52:06.720] receive send all
[52:06.720 --> 52:07.920] send all是UDP的
[52:07.920 --> 52:13.600] 但是你这种BCC的方式可以把它放到
[52:13.600 --> 52:18.720] 怎么说就是说这个latency不是一定能复现的
[52:18.720 --> 52:21.600] 它是有的时候一整天都没有
[52:21.600 --> 52:23.279] 你长期跑呗
[52:23.279 --> 52:24.640] 你采样跑吧
[52:24.640 --> 52:26.880] 就说你采对可以采样
[52:26.880 --> 52:29.600] BCC长期跑就好了
[52:29.600 --> 52:32.640] BCC最大的好处就是他对性能压很低
[52:32.640 --> 52:35.040] 等一下我们在聊工具的时候会专门聊到
[52:35.040 --> 52:35.920] 对可以在聊
[52:35.920 --> 52:37.040] 你可以随时跑
[52:37.040 --> 52:40.160] 然后而且性能省号相对来说其实没有你想象那么大
[52:40.160 --> 52:41.600] 如果说你不去做
[52:41.600 --> 52:43.040] 基本没有
[52:43.040 --> 52:44.400] 没有还是有的
[52:44.400 --> 52:46.720] 线上我错过线上流量大的时候
[52:46.720 --> 52:48.800] 还是流量大的长期跑的话
[52:48.800 --> 52:52.080] 跑那个就K-probe的那些hook的话
[52:52.080 --> 52:55.600] 还是那个就是说是代价还在那的
[52:55.600 --> 52:58.640] 然后因为就是说是整体的水位和CPU的那个
[52:58.640 --> 53:01.279] 就如果说你的那个量特别大的话
[53:01.279 --> 53:03.200] 要看你做什么事情
[53:03.200 --> 53:06.560] 我们回调做一个简单的数据采集的话还是很简单的
[53:06.560 --> 53:08.960] 对是如果是相对来说
[53:08.960 --> 53:11.200] 其实代价还是就已经是比较小的了
[53:11.200 --> 53:13.520] 如果说用其他方法那已经是非常炸了
[53:16.319 --> 53:19.040] 我之前遇到个比较有意思的问题
[53:19.040 --> 53:20.799] 然后是跟Malloc相关的
[53:20.799 --> 53:22.960] 当然这个其实是python的经典的问题
[53:22.960 --> 53:24.480] 然后又是跟python有关的
[53:24.480 --> 53:26.319] 当然其实这个python不背锅
[53:26.319 --> 53:32.720] 然后就当时是我们线上服务的内存水位一直在涨
[53:33.600 --> 53:38.399] 然后就这个时候你第一反应肯定说内存泄漏了
[53:38.400 --> 53:43.840] 然后就反正就一直在飙就很缓慢的曲线
[53:43.840 --> 53:45.680] 然后你一直在飙之后
[53:45.680 --> 53:50.080] 然后你第一反应肯定说是内存泄漏对吧
[53:50.080 --> 53:52.000] 然后就像Grayso的你首先要确认
[53:52.000 --> 53:53.760] 这个到底是应用的问题还是什么的问题
[53:53.760 --> 53:56.800] 然后你第一反应就是你是内存泄漏了
[53:56.800 --> 53:59.840] 然后用了一些方法hook进去了
[53:59.840 --> 54:02.960] 然后hook进去去看它里面GC的那些状态
[54:02.960 --> 54:06.000] 就是说是首先我们review业务代码没有出现
[54:06.000 --> 54:07.920] 就是说是就那种循环引用
[54:07.920 --> 54:10.560] 虽然在3.4以后循环引用大部分也都可以释放了
[54:10.560 --> 54:13.920] 然后就说是没有就说是长期持有的那些
[54:13.920 --> 54:15.840] 就说是那部分其实还好
[54:15.840 --> 54:17.520] 然后我们去调GC的话
[54:18.080 --> 54:20.640] 他的GC的那些状态也是正常的
[54:20.640 --> 54:24.320] 然后也说是其实排除了就说是业务代码这块问题
[54:24.320 --> 54:30.080] 那这个时候可能说是就去看那一块的
[54:30.080 --> 54:33.360] 就说是python的本身的问题
[54:33.360 --> 54:34.640] python本身的问题
[54:34.640 --> 54:38.160] 然后去看python它的内存池
[54:38.160 --> 54:41.120] 就说是用一些方法去就是说是重编译python
[54:41.120 --> 54:42.240] 看它的内存池
[54:42.240 --> 54:44.960] 就比如说它的内存块之类的那些东西
[54:44.960 --> 54:47.040] 和GC的状态是否能对上
[54:47.040 --> 54:48.480] 然后其实也能对上
[54:48.480 --> 54:50.160] 也就说是没有太大的东西
[54:50.160 --> 54:52.480] GLABC的MELOC的国
[54:52.480 --> 54:54.400] 就说是你GLABC的MELOC的话
[54:54.400 --> 54:56.240] 就说是它分为两个机制
[54:56.240 --> 54:57.759] BRK和MMAP
[54:57.759 --> 55:00.480] 然后就是BRK就说是MELOC
[55:00.480 --> 55:02.720] GLABC的MELOC它自己的一个内存池
[55:02.720 --> 55:04.480] 就说你小于128K的时候
[55:04.480 --> 55:06.160] 你去走BRK
[55:06.160 --> 55:08.960] 然后大的时候它会直接给你走MMAP
[55:08.960 --> 55:10.640] 然后你BRK
[55:10.640 --> 55:12.240] 然后它申请了BRK的话
[55:12.240 --> 55:13.840] 它默认的情况下是
[55:13.840 --> 55:18.320] 就是说它的就是说是它后面就说是BRK
[55:18.320 --> 55:19.840] 随着你的增加而增加
[55:19.840 --> 55:22.000] 就说是它一直不会释放你的内存
[55:22.000 --> 55:23.440] 就说即便你python里面
[55:23.440 --> 55:25.200] 比如说你的那些内存破
[55:25.200 --> 55:27.760] 已经把这个内存选择free给操作系统了
[55:27.760 --> 55:31.680] 但是它因为它BRK本就是GLABC这个层面上来讲
[55:31.680 --> 55:32.960] 它的BRK本身是一个
[55:32.960 --> 55:35.040] 就说是memory pool
[55:35.040 --> 55:37.600] 就是说你是避免重复的去MMAP了
[55:37.600 --> 55:40.640] 然后那么就你除非到了水位很高的时候
[55:40.640 --> 55:42.000] 它才会去释放
[55:42.000 --> 55:43.920] 然后后面去调整一些
[55:43.920 --> 55:47.360] 那个就说是那个就第1个
[55:47.360 --> 55:49.520] 就说是调整它的那个随时hold
[55:49.520 --> 55:52.960] 就是说是调整它的那个就是释放预值
[55:52.960 --> 55:54.400] 把它固定在128
[55:54.400 --> 55:57.760] 然后就说是后面释放水位降下来了
[55:57.760 --> 56:00.800] 然后在另外一部分的话
[56:00.800 --> 56:03.440] 就说是我们就选择就直接一步到位
[56:03.440 --> 56:08.080] 切换到了就说是like9m他们家的那个TCMLOCK
[56:08.080 --> 56:10.960] 然后就把就说是性能更好
[56:10.960 --> 56:12.640] 然后内存占用更低
[56:12.640 --> 56:14.960] 就是说是释放策略更优秀一些
[56:14.960 --> 56:19.120] 对这个问题确实也是就我当时觉得挺有趣的
[56:19.120 --> 56:23.200] 然后因为你去首先查应用程本身
[56:23.200 --> 56:26.560] 然后去改一部分cpy的东西把它给输出出来
[56:26.560 --> 56:27.760] 就是说状态
[56:27.760 --> 56:33.040] 然后最后定位到具体可能的问题
[56:33.040 --> 56:35.600] 然后这个其实之前在华网上也有过讨论
[56:35.600 --> 56:36.800] 但是这个就是很经典
[56:36.800 --> 56:39.600] 但是没有还没搜到那个具体的结论吧
[56:40.640 --> 56:46.320] 好像现在微就是我记得有人提议说要把cpy的那个
[56:46.320 --> 56:50.240] 就是从BLOCK换成微软的一个那个叫什么
[56:52.080 --> 56:54.960] 也是一个忘记名字了
[56:54.960 --> 56:57.920] 但是说实话我觉得其实挺难的
[56:57.920 --> 57:02.880] 因为我觉得这个东西然后就还是涉及到挺多东西的
[57:06.160 --> 57:10.560] BLK申请内存是不是就是申请
[57:10.560 --> 57:13.920] 然后当天不够的话他就给你移动那个BLK
[57:13.920 --> 57:17.520] 那个内存的那个BLK的那个占不是这样
[57:17.520 --> 57:19.280] 就是更多
[57:19.280 --> 57:21.360] 但是你不用了他不会给你释放
[57:21.360 --> 57:25.040] 但是你下次再申请下次再申请
[57:25.040 --> 57:29.200] 如果他那个进程BLK之内的内存如果够的话
[57:29.200 --> 57:31.760] 他就直接给你返回之前的
[57:31.760 --> 57:34.160] 对他最开始是限定在128的
[57:34.160 --> 57:37.040] 他最开始是限定在128后面哪个版本
[57:37.040 --> 57:39.200] 我一下就没查到扣的资料
[57:39.200 --> 57:40.560] 就说是把它改成动态了
[57:40.560 --> 57:41.840] 就是说你刚才说的
[57:41.840 --> 57:45.040] 然后他不够他又给新的就扩大给你申请新的
[57:45.040 --> 57:46.720] 然后暂时又不会归换给系统
[57:46.720 --> 57:51.839] 这样的话你就申请内存
[57:51.839 --> 57:55.040] 然后BLK之内的没有能没有连续内存能满足的
[57:55.040 --> 57:56.799] 他就再扩大BLK
[57:56.799 --> 57:59.839] 然后就除非是道理的内存水位很高了
[57:59.839 --> 58:02.399] 他才会触发一个就是说是彻底把BLK里面
[58:02.399 --> 58:04.399] 那一部分的就是给释放的一个操作
[58:04.399 --> 58:08.480] 好像Golang的1.12之后有那个
[58:08.480 --> 58:14.080] 有一个参数叫MADV free是吧
[58:14.080 --> 58:15.839] 他也是这样
[58:15.840 --> 58:18.720] 就是具体的表现就是Golang的1.12之后
[58:18.720 --> 58:22.400] 默认的行为是Golang如果申请了内存
[58:22.400 --> 58:26.960] 但是你用完了Golang不会把它还给操作系统
[58:26.960 --> 58:30.400] 然后如果你下次在Golang里面再申请这个内存
[58:30.400 --> 58:34.320] Golang会从他没还的这些内存里面去给你申请
[58:34.320 --> 58:37.920] 但是从操作系统上来看
[58:37.920 --> 58:41.040] 除非就是说其他有进程再申请内存
[58:41.040 --> 58:42.240] 操作系统给不出来了
[58:42.240 --> 58:45.760] 他才会把Golang没有还给操作系统的部分
[58:45.760 --> 58:47.280] 就是Golang才开始还
[58:47.280 --> 58:51.680] 否则的话你会看到Golang的那个进程的内存
[58:51.680 --> 58:53.040] 它只增不减的
[58:53.040 --> 58:55.360] 除非操作系统内存够用了
[58:55.360 --> 59:00.080] 然后就这种行为你可以写一个小程序来验证
[59:00.080 --> 59:03.360] 叫memory balloon内存气球
[59:03.360 --> 59:05.600] 就是说你一直申请内存一直申请内存
[59:05.600 --> 59:07.360] 然后你可以发现
[59:07.360 --> 59:09.440] 为什么要写这个东西呢
[59:09.440 --> 59:11.680] 就是因为我们不知道到底是Golang的问题
[59:11.680 --> 59:14.160] 还是说真的我们的应用内存泄露了吗
[59:14.160 --> 59:15.839] 然后你写个memory balloon
[59:15.839 --> 59:18.960] 你会发现最后你如果申请的内存
[59:18.960 --> 59:20.560] 把操作系统内存申请光了
[59:20.560 --> 59:22.879] 那个Golang就开始还内存了
[59:22.879 --> 59:26.640] 就是这个也是个优化
[59:26.640 --> 59:30.640] 我觉得像这种礼拜就依赖于你知道这个behavior
[59:30.640 --> 59:34.640] 对 但是其实我当时不太知道这个behavior
[59:34.640 --> 59:37.040] 也是就是说是先去排除
[59:37.040 --> 59:38.640] 然后尽可能在能力范围内
[59:38.640 --> 59:41.040] 就比如说我先去分析他的GC状态正常的
[59:41.040 --> 59:43.600] 然后Python本身的内存池的状态是正常的
[59:43.600 --> 59:45.600] 然后因为我当时重新recompile
[59:45.600 --> 59:47.759] 就是整个一体的recompile
[59:47.759 --> 59:49.360] 就Cpython的那个
[59:49.360 --> 59:50.480] 然后在线上
[59:50.480 --> 59:53.040] 对 然后那么这个东西是正常的
[59:53.040 --> 59:55.920] 然后最后才定位就可能说是Metalcore的问题
[59:57.920 --> 01:00:02.160] 其实这个可以用那个虽然不太好确定
[01:00:02.160 --> 01:00:03.279] 某一个commit是好
[01:00:03.279 --> 01:00:05.759] 但是可以用git bsect来发现
[01:00:05.759 --> 01:00:09.759] 那个commit引入就是把Golang的build版本给升级了
[01:00:09.759 --> 01:00:12.720] 然后你去看Golang1.12的change log
[01:00:12.720 --> 01:00:16.240] 它会明确的说他们加了一个这个默认的行为
[01:00:16.240 --> 01:00:19.120] 但是你可以修改一个environment variable
[01:00:19.120 --> 01:00:20.560] 把这个东西给关掉
[01:00:20.560 --> 01:00:22.560] 然后revert到之前的行为
[01:00:22.560 --> 01:00:24.959] 这个问题其实很有意思
[01:00:24.959 --> 01:00:26.240] 它没有造成任何的问题
[01:00:26.240 --> 01:00:28.640] 但是它给我们监控造成了很大的困难
[01:00:28.640 --> 01:00:31.839] 就是说你任何的监控工具你去看Golang
[01:00:31.839 --> 01:00:36.000] 它都是真的就是有这么多内存申请了
[01:00:36.000 --> 01:00:38.799] 因为从操作系统看这个进程就是这样子的
[01:00:38.799 --> 01:00:40.799] 你也没办法说它到底是
[01:00:40.800 --> 01:00:44.320] 这个Golang的正常行为还是内存泄漏了
[01:00:44.320 --> 01:00:45.920] 除非你把它关掉
[01:00:45.920 --> 01:00:48.320] 关掉的话就性能会下降一部分
[01:00:48.320 --> 01:00:50.640] 确实比较难搞
[01:00:50.640 --> 01:00:55.680] 你可以监控Golang进程内部自己暴露出来的一个metric
[01:00:55.680 --> 01:00:56.800] 叫heap size
[01:00:56.800 --> 01:00:59.760] 但是这个如果你得相信Golang
[01:00:59.760 --> 01:01:01.600] 如果说它这个metric写错了的话
[01:01:01.600 --> 01:01:04.080] 就没说了
[01:01:04.080 --> 01:01:05.600] 这个很奇怪
[01:01:05.600 --> 01:01:07.840] 这个很奇怪
[01:01:07.840 --> 01:01:10.240] Golang1.16又把这个行为给改回去了
[01:01:10.240 --> 01:01:13.680] 就是说默认Golang用完了内存就回来
[01:01:13.680 --> 01:01:16.399] 之前Python还有个很经典的问题
[01:01:16.399 --> 01:01:18.399] 就是它3.2的时候
[01:01:18.399 --> 01:01:23.680] 之前和周浩尔在那个就是说是那个关于regress
[01:01:23.680 --> 01:01:26.080] 那个就是那个政治表达室那个
[01:01:26.080 --> 01:01:29.200] 就之前大家说就是说你比如说R1.compile
[01:01:29.200 --> 01:01:31.759] R1.compile的时候它会给你做一个cache
[01:01:31.759 --> 01:01:33.279] 对做一个cache
[01:01:33.279 --> 01:01:35.680] 然后早期版本的时候
[01:01:35.680 --> 01:01:38.640] 然后最开始是没有做缓存好像是什么的
[01:01:38.640 --> 01:01:40.960] 然后后面然后做了一个LRU
[01:01:40.960 --> 01:01:43.600] 然后没有限制
[01:01:43.600 --> 01:01:46.000] 然后就3.2的时候好像是做了一个LRU
[01:01:46.000 --> 01:01:48.400] 然后那么3.24的时候
[01:01:48.400 --> 01:01:50.560] 当时又把LRU给改回去
[01:01:50.560 --> 01:01:54.000] 因为发现就是当时它没有去限制它的那个buffer size
[01:01:54.000 --> 01:01:58.160] 导致说你这compile很多的情况下
[01:01:58.160 --> 01:02:01.440] 然后它就直接给你那个就是你参数一变或什么
[01:02:01.440 --> 01:02:02.879] 都可以生成一个新的LRU
[01:02:02.879 --> 01:02:03.920] 就说你内存炸了
[01:02:03.920 --> 01:02:06.240] 反正就是开源社区反复横跳
[01:02:06.240 --> 01:02:07.759] 倒是个很经典的现象
[01:02:07.760 --> 01:02:10.640] 就刚刚我想提一点就是你升级框架
[01:02:10.640 --> 01:02:11.920] 或者依赖code版本
[01:02:11.920 --> 01:02:13.920] 或者像光亮版本这样的东西
[01:02:13.920 --> 01:02:16.080] 一定要把change log给读一遍
[01:02:16.080 --> 01:02:19.760] 这样可以减少很多不必要的工作
[01:02:19.760 --> 01:02:22.320] 对我其实想说也是这个问题
[01:02:22.320 --> 01:02:26.800] 就是那个读change log有时候真的是一条shortcut
[01:02:26.800 --> 01:02:30.320] 就是之前那个就是想
[01:02:30.320 --> 01:02:34.000] 再把就是给cyberbrain加3.10的支持
[01:02:34.000 --> 01:02:38.480] 然后3.10里其实做了很多修改
[01:02:38.480 --> 01:02:41.360] 然后我发现有一个很有意思的问题
[01:02:41.360 --> 01:02:43.840] 就是你们知道就是python是bytecode
[01:02:43.840 --> 01:02:45.360] 然后原来它的一个
[01:02:45.360 --> 01:02:50.640] 就是它的里面那个bytecode的跳转的单位是一个byte
[01:02:50.640 --> 01:02:53.520] 然后后来我就发现
[01:02:53.520 --> 01:02:56.720] 不知道为什么3.10里面那个跳转的参数
[01:02:56.720 --> 01:02:58.000] 就是跟原来对不上
[01:02:58.000 --> 01:03:00.480] 然后就去看change log
[01:03:00.480 --> 01:03:04.320] 然后发现它其实是把那个跳转这个数由一个byte
[01:03:04.320 --> 01:03:05.840] 变成了一个instruction
[01:03:05.840 --> 01:03:08.640] 就相当于因为一个instruction是两个byte
[01:03:08.640 --> 01:03:11.360] 所以它相当于都是就减半了
[01:03:11.360 --> 01:03:14.640] 然后就是我去看change log
[01:03:14.640 --> 01:03:15.680] 还是别人告诉我说
[01:03:15.680 --> 01:03:19.680] 就是python的那个bytecode有一个magic number
[01:03:19.680 --> 01:03:21.920] 然后它那个magic number相当于就是说
[01:03:21.920 --> 01:03:24.560] 你每次bytecode有一个incompatible change
[01:03:24.560 --> 01:03:27.600] 它就会去变那个byte就是那个magic number
[01:03:27.600 --> 01:03:32.720] 然后我就去看就是那个找到那个magic number的那个页面
[01:03:32.720 --> 01:03:35.600] 然后去把那个blame打开
[01:03:35.600 --> 01:03:36.560] 就在github上
[01:03:36.560 --> 01:03:38.319] 然后他就很清楚就是说
[01:03:38.319 --> 01:03:41.680] 那个这次有什么change
[01:03:41.680 --> 01:03:43.440] 然后就是一个很方便的
[01:03:43.440 --> 01:03:46.000] 就是能看到变化的方法
[01:03:46.000 --> 01:03:48.480] 所以就是看change log有时候真的还是挺好
[01:03:48.480 --> 01:03:53.680] 好那么我们这一期聊大家的debug的经历就聊这么多
[01:03:53.680 --> 01:03:58.480] 我们聊了一些主播跟Grey遇到的一些印象比较深刻
[01:03:58.480 --> 01:04:01.120] 或者比较难debug的一些经历
[01:04:01.120 --> 01:04:03.919] 然后聊到了一些debug的方法论
[01:04:03.919 --> 01:04:06.240] 这就是本期的内容了
[01:04:06.240 --> 01:04:09.359] 我们下一期会聊一些debug的工具
[01:04:09.359 --> 01:04:15.440] 看有什么方法能帮助我们在debug的过程中少花一些工作
[01:04:15.440 --> 01:04:16.720] 让我们事半功倍
[01:04:16.720 --> 01:04:18.399] 感谢大家的收听
[01:04:18.400 --> 01:04:24.560] 欢迎大家继续收听下一期
